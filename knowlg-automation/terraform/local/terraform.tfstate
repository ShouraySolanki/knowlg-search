{
  "version": 4,
  "terraform_version": "1.4.2",
  "serial": 213,
  "lineage": "9487d65f-b5a7-e87c-8d2c-35cd1692aa74",
  "outputs": {},
  "resources": [
    {
      "mode": "managed",
      "type": "helm_release",
      "name": "cassandra",
      "provider": "provider[\"registry.terraform.io/hashicorp/helm\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "atomic": false,
            "chart": "../../helm_charts/cassandra",
            "cleanup_on_fail": false,
            "create_namespace": true,
            "dependency_update": true,
            "description": null,
            "devel": null,
            "disable_crd_hooks": false,
            "disable_openapi_validation": false,
            "disable_webhooks": false,
            "force_update": false,
            "id": "cassandra",
            "keyring": null,
            "lint": false,
            "manifest": null,
            "max_history": 0,
            "metadata": [
              {
                "app_version": "1.0",
                "chart": "cassandra",
                "name": "cassandra",
                "namespace": "knowlg-db",
                "revision": 1,
                "values": "null",
                "version": "0.1.0"
              }
            ],
            "name": "cassandra",
            "namespace": "knowlg-db",
            "pass_credentials": false,
            "postrender": [],
            "recreate_pods": false,
            "render_subchart_notes": true,
            "replace": false,
            "repository": null,
            "repository_ca_file": null,
            "repository_cert_file": null,
            "repository_key_file": null,
            "repository_password": null,
            "repository_username": null,
            "reset_values": false,
            "reuse_values": false,
            "set": [],
            "set_sensitive": [],
            "skip_crds": false,
            "status": "deployed",
            "timeout": 300,
            "values": null,
            "verify": false,
            "version": "0.1.0",
            "wait": true,
            "wait_for_jobs": true
          },
          "sensitive_attributes": [],
          "private": "bnVsbA==",
          "dependencies": [
            "kind_cluster.one-click"
          ]
        }
      ]
    },
    {
      "mode": "managed",
      "type": "helm_release",
      "name": "elasticsearch",
      "provider": "provider[\"registry.terraform.io/hashicorp/helm\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "atomic": false,
            "chart": "../../helm_charts/elasticsearch",
            "cleanup_on_fail": false,
            "create_namespace": true,
            "dependency_update": true,
            "description": null,
            "devel": null,
            "disable_crd_hooks": false,
            "disable_openapi_validation": false,
            "disable_webhooks": false,
            "force_update": false,
            "id": "elasticsearch",
            "keyring": null,
            "lint": false,
            "manifest": null,
            "max_history": 0,
            "metadata": [
              {
                "app_version": "8.6.0",
                "chart": "elasticsearch",
                "name": "elasticsearch",
                "namespace": "knowlg-db",
                "revision": 1,
                "values": "null",
                "version": "19.5.8"
              }
            ],
            "name": "elasticsearch",
            "namespace": "knowlg-db",
            "pass_credentials": false,
            "postrender": [],
            "recreate_pods": false,
            "render_subchart_notes": true,
            "replace": false,
            "repository": null,
            "repository_ca_file": null,
            "repository_cert_file": null,
            "repository_key_file": null,
            "repository_password": null,
            "repository_username": null,
            "reset_values": false,
            "reuse_values": false,
            "set": [],
            "set_sensitive": [],
            "skip_crds": false,
            "status": "deployed",
            "timeout": 300,
            "values": null,
            "verify": false,
            "version": "19.5.8",
            "wait": true,
            "wait_for_jobs": true
          },
          "sensitive_attributes": [],
          "private": "bnVsbA==",
          "dependencies": [
            "kind_cluster.one-click"
          ]
        }
      ]
    },
    {
      "mode": "managed",
      "type": "helm_release",
      "name": "kafka",
      "provider": "provider[\"registry.terraform.io/hashicorp/helm\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "atomic": false,
            "chart": "../../helm_charts/kafka",
            "cleanup_on_fail": false,
            "create_namespace": true,
            "dependency_update": true,
            "description": null,
            "devel": null,
            "disable_crd_hooks": false,
            "disable_openapi_validation": false,
            "disable_webhooks": false,
            "force_update": false,
            "id": "kafka",
            "keyring": null,
            "lint": false,
            "manifest": null,
            "max_history": 0,
            "metadata": [
              {
                "app_version": "3.3.1",
                "chart": "kafka",
                "name": "kafka",
                "namespace": "knowlg-db",
                "revision": 1,
                "values": "{\"advertisedListeners\":[],\"affinity\":{},\"allowEveryoneIfNoAclFound\":true,\"allowPlaintextListener\":true,\"args\":[],\"auth\":{\"clientProtocol\":\"plaintext\",\"externalClientProtocol\":\"\",\"interBrokerProtocol\":\"plaintext\",\"sasl\":{\"interBrokerMechanism\":\"plain\",\"jaas\":{\"clientPasswords\":[],\"clientUsers\":[\"user\"],\"existingSecret\":\"\",\"interBrokerPassword\":\"\",\"interBrokerUser\":\"admin\",\"zookeeperPassword\":\"\",\"zookeeperUser\":\"\"},\"mechanisms\":\"plain,scram-sha-256,scram-sha-512\"},\"tls\":{\"autoGenerated\":false,\"endpointIdentificationAlgorithm\":\"https\",\"existingSecret\":\"\",\"existingSecrets\":[],\"jksKeystoreSAN\":\"\",\"jksTruststore\":\"\",\"jksTruststoreSecret\":\"\",\"password\":\"\",\"pemChainIncluded\":false,\"type\":\"jks\"},\"zookeeper\":{\"tls\":{\"enabled\":false,\"existingSecret\":\"\",\"existingSecretKeystoreKey\":\"zookeeper.keystore.jks\",\"existingSecretTruststoreKey\":\"zookeeper.truststore.jks\",\"passwordsSecret\":\"\",\"passwordsSecretKeystoreKey\":\"keystore-password\",\"passwordsSecretTruststoreKey\":\"truststore-password\",\"type\":\"jks\",\"verifyHostname\":true}}},\"authorizerClassName\":\"\",\"autoCreateTopicsEnable\":true,\"brokerRackAssignment\":\"\",\"clusterDomain\":\"cluster.local\",\"command\":[\"/scripts/setup.sh\"],\"commonAnnotations\":{},\"commonLabels\":{},\"config\":\"\",\"containerPorts\":{\"client\":9092,\"external\":9094,\"internal\":9093},\"containerSecurityContext\":{\"allowPrivilegeEscalation\":false,\"enabled\":true,\"runAsNonRoot\":true,\"runAsUser\":1001},\"customLivenessProbe\":{},\"customReadinessProbe\":{},\"customStartupProbe\":{},\"defaultReplicationFactor\":1,\"deleteTopicEnable\":false,\"diagnosticMode\":{\"args\":[\"infinity\"],\"command\":[\"sleep\"],\"enabled\":false},\"existingConfigmap\":\"\",\"existingLog4jConfigMap\":\"\",\"externalAccess\":{\"autoDiscovery\":{\"enabled\":false,\"image\":{\"digest\":\"\",\"pullPolicy\":\"IfNotPresent\",\"pullSecrets\":[],\"registry\":\"docker.io\",\"repository\":\"bitnami/kubectl\",\"tag\":\"1.25.5-debian-11-r2\"},\"resources\":{\"limits\":{},\"requests\":{}}},\"enabled\":false,\"service\":{\"annotations\":{},\"domain\":\"\",\"extraPorts\":[],\"labels\":{},\"loadBalancerAnnotations\":[],\"loadBalancerIPs\":[],\"loadBalancerNames\":[],\"loadBalancerSourceRanges\":[],\"nodePorts\":[],\"ports\":{\"external\":9094},\"publishNotReadyAddresses\":false,\"type\":\"LoadBalancer\",\"useHostIPs\":false,\"usePodIPs\":false}},\"externalZookeeper\":{\"servers\":[]},\"extraDeploy\":[],\"extraEnvVars\":[],\"extraEnvVarsCM\":\"\",\"extraEnvVarsSecret\":\"\",\"extraVolumeMounts\":[],\"extraVolumes\":[],\"fullnameOverride\":\"\",\"global\":{\"imagePullSecrets\":[],\"imageRegistry\":\"\",\"storageClass\":\"\"},\"heapOpts\":\"-Xmx1024m -Xms1024m\",\"hostAliases\":[],\"hostIPC\":false,\"hostNetwork\":false,\"image\":{\"debug\":false,\"digest\":\"\",\"pullPolicy\":\"IfNotPresent\",\"pullSecrets\":[],\"registry\":\"docker.io\",\"repository\":\"bitnami/kafka\",\"tag\":\"3.3.1-debian-11-r25\"},\"initContainers\":[],\"interBrokerListenerName\":\"INTERNAL\",\"kubeVersion\":\"\",\"lifecycleHooks\":{},\"listenerSecurityProtocolMap\":\"\",\"listeners\":[],\"livenessProbe\":{\"enabled\":true,\"failureThreshold\":3,\"initialDelaySeconds\":10,\"periodSeconds\":10,\"successThreshold\":1,\"timeoutSeconds\":5},\"log4j\":\"\",\"logFlushIntervalMessages\":\"_10000\",\"logFlushIntervalMs\":1000,\"logPersistence\":{\"accessModes\":[\"ReadWriteOnce\"],\"annotations\":{},\"enabled\":false,\"existingClaim\":\"\",\"mountPath\":\"/opt/bitnami/kafka/logs\",\"selector\":{},\"size\":\"8Gi\",\"storageClass\":\"\"},\"logRetentionBytes\":\"_1073741824\",\"logRetentionCheckIntervalMs\":300000,\"logRetentionHours\":168,\"logSegmentBytes\":\"_1073741824\",\"logsDirs\":\"/bitnami/kafka/data\",\"maxMessageBytes\":\"_1000012\",\"metrics\":{\"jmx\":{\"config\":\"jmxUrl: service:jmx:rmi:///jndi/rmi://127.0.0.1:5555/jmxrmi\\nlowercaseOutputName: true\\nlowercaseOutputLabelNames: true\\nssl: false\\n{{- if .Values.metrics.jmx.whitelistObjectNames }}\\nwhitelistObjectNames: [\\\"{{ join \\\"\\\\\\\",\\\\\\\"\\\" .Values.metrics.jmx.whitelistObjectNames }}\\\"]\\n{{- end }}\",\"containerPorts\":{\"metrics\":5556},\"containerSecurityContext\":{\"enabled\":true,\"runAsNonRoot\":true,\"runAsUser\":1001},\"enabled\":false,\"existingConfigmap\":\"\",\"extraRules\":\"\",\"image\":{\"digest\":\"\",\"pullPolicy\":\"IfNotPresent\",\"pullSecrets\":[],\"registry\":\"docker.io\",\"repository\":\"bitnami/jmx-exporter\",\"tag\":\"0.17.2-debian-11-r29\"},\"resources\":{\"limits\":{},\"requests\":{}},\"service\":{\"annotations\":{\"prometheus.io/path\":\"/\",\"prometheus.io/port\":\"{{ .Values.metrics.jmx.service.ports.metrics }}\",\"prometheus.io/scrape\":\"true\"},\"clusterIP\":\"\",\"ports\":{\"metrics\":5556},\"sessionAffinity\":\"None\"},\"whitelistObjectNames\":[\"kafka.controller:*\",\"kafka.server:*\",\"java.lang:*\",\"kafka.network:*\",\"kafka.log:*\"]},\"kafka\":{\"affinity\":{},\"args\":[],\"certificatesSecret\":\"\",\"command\":[],\"containerPorts\":{\"metrics\":9308},\"containerSecurityContext\":{\"enabled\":true,\"runAsNonRoot\":true,\"runAsUser\":1001},\"enabled\":false,\"extraFlags\":{},\"extraVolumeMounts\":[],\"extraVolumes\":[],\"hostAliases\":[],\"image\":{\"digest\":\"\",\"pullPolicy\":\"IfNotPresent\",\"pullSecrets\":[],\"registry\":\"docker.io\",\"repository\":\"bitnami/kafka-exporter\",\"tag\":\"1.6.0-debian-11-r40\"},\"initContainers\":[],\"nodeAffinityPreset\":{\"key\":\"\",\"type\":\"\",\"values\":[]},\"nodeSelector\":{},\"podAffinityPreset\":\"\",\"podAnnotations\":{},\"podAntiAffinityPreset\":\"soft\",\"podLabels\":{},\"podSecurityContext\":{\"enabled\":true,\"fsGroup\":1001},\"priorityClassName\":\"\",\"resources\":{\"limits\":{},\"requests\":{}},\"schedulerName\":\"\",\"service\":{\"annotations\":{\"prometheus.io/path\":\"/metrics\",\"prometheus.io/port\":\"{{ .Values.metrics.kafka.service.ports.metrics }}\",\"prometheus.io/scrape\":\"true\"},\"clusterIP\":\"\",\"ports\":{\"metrics\":9308},\"sessionAffinity\":\"None\"},\"serviceAccount\":{\"automountServiceAccountToken\":true,\"create\":true,\"name\":\"\"},\"sidecars\":[],\"tlsCaCert\":\"ca-file\",\"tlsCaSecret\":\"\",\"tlsCert\":\"cert-file\",\"tlsKey\":\"key-file\",\"tolerations\":[],\"topologySpreadConstraints\":[]},\"prometheusRule\":{\"enabled\":false,\"groups\":[],\"labels\":{},\"namespace\":\"\"},\"serviceMonitor\":{\"enabled\":false,\"honorLabels\":false,\"interval\":\"\",\"jobLabel\":\"\",\"labels\":{},\"metricRelabelings\":[],\"namespace\":\"\",\"relabelings\":[],\"scrapeTimeout\":\"\",\"selector\":{}}},\"minBrokerId\":0,\"nameOverride\":\"\",\"networkPolicy\":{\"allowExternal\":true,\"egressRules\":{\"customRules\":[]},\"enabled\":false,\"explicitNamespacesSelector\":{},\"externalAccess\":{\"from\":[]}},\"nodeAffinityPreset\":{\"key\":\"\",\"type\":\"\",\"values\":[]},\"nodeSelector\":{},\"numIoThreads\":8,\"numNetworkThreads\":3,\"numPartitions\":1,\"numRecoveryThreadsPerDataDir\":1,\"offsetsTopicReplicationFactor\":1,\"pdb\":{\"create\":false,\"maxUnavailable\":1,\"minAvailable\":\"\"},\"persistence\":{\"accessModes\":[\"ReadWriteOnce\"],\"annotations\":{},\"enabled\":true,\"existingClaim\":\"\",\"labels\":{},\"mountPath\":\"/bitnami/kafka\",\"selector\":{},\"size\":\"8Gi\",\"storageClass\":\"\"},\"podAffinityPreset\":\"\",\"podAnnotations\":{},\"podAntiAffinityPreset\":\"soft\",\"podLabels\":{},\"podManagementPolicy\":\"Parallel\",\"podSecurityContext\":{\"enabled\":true,\"fsGroup\":1001},\"priorityClassName\":\"\",\"provisioning\":{\"args\":[],\"auth\":{\"tls\":{\"caCert\":\"ca.crt\",\"cert\":\"tls.crt\",\"certificatesSecret\":\"\",\"key\":\"tls.key\",\"keyPassword\":\"\",\"keyPasswordSecretKey\":\"key-password\",\"keystore\":\"keystore.jks\",\"keystorePassword\":\"\",\"keystorePasswordSecretKey\":\"keystore-password\",\"passwordsSecret\":\"\",\"truststore\":\"truststore.jks\",\"truststorePassword\":\"\",\"truststorePasswordSecretKey\":\"truststore-password\",\"type\":\"jks\"}},\"command\":[],\"containerSecurityContext\":{\"enabled\":true,\"runAsNonRoot\":true,\"runAsUser\":1001},\"enabled\":true,\"extraEnvVars\":[],\"extraEnvVarsCM\":\"\",\"extraEnvVarsSecret\":\"\",\"extraProvisioningCommands\":[],\"extraVolumeMounts\":[],\"extraVolumes\":[],\"initContainers\":[],\"nodeSelector\":{},\"numPartitions\":1,\"parallel\":1,\"podAnnotations\":{},\"podLabels\":{},\"podSecurityContext\":{\"enabled\":true,\"fsGroup\":1001},\"postScript\":\"\",\"preScript\":\"\",\"replicationFactor\":1,\"resources\":{\"limits\":{},\"requests\":{}},\"schedulerName\":\"\",\"serviceAccount\":{\"automountServiceAccountToken\":true,\"create\":false,\"name\":\"\"},\"sidecars\":[],\"tolerations\":[],\"topics\":[{\"config\":{\"flush.messages\":1,\"max.message.bytes\":64000},\"name\":\"dev.telemetry.denorm\",\"partitions\":1,\"replicationFactor\":1},{\"config\":{\"flush.messages\":1,\"max.message.bytes\":64000},\"name\":\"dev.druid.events.telemetry\",\"partitions\":1,\"replicationFactor\":1},{\"config\":{\"flush.messages\":1,\"max.message.bytes\":64000},\"name\":\"dev.druid.events.summary\",\"partitions\":1,\"replicationFactor\":1},{\"config\":{\"flush.messages\":1,\"max.message.bytes\":64000},\"name\":\"dev.telemetry.failed\",\"partitions\":1,\"replicationFactor\":1},{\"config\":{\"flush.messages\":1,\"max.message.bytes\":64000},\"name\":\"dev.telemetry.duplicate\",\"partitions\":1,\"replicationFactor\":1}],\"waitForKafka\":true},\"rbac\":{\"create\":false},\"readinessProbe\":{\"enabled\":true,\"failureThreshold\":6,\"initialDelaySeconds\":5,\"periodSeconds\":10,\"successThreshold\":1,\"timeoutSeconds\":5},\"replicaCount\":1,\"resources\":{\"limits\":{},\"requests\":{}},\"schedulerName\":\"\",\"service\":{\"annotations\":{},\"clusterIP\":\"\",\"externalTrafficPolicy\":\"Cluster\",\"extraPorts\":[],\"headless\":{\"annotations\":{},\"labels\":{},\"publishNotReadyAddresses\":false},\"loadBalancerIP\":\"\",\"loadBalancerSourceRanges\":[],\"nodePorts\":{\"client\":\"\",\"external\":\"\"},\"ports\":{\"client\":9092,\"external\":9094,\"internal\":9093},\"sessionAffinity\":\"None\",\"sessionAffinityConfig\":{},\"type\":\"ClusterIP\"},\"serviceAccount\":{\"annotations\":{},\"automountServiceAccountToken\":true,\"create\":true,\"name\":\"\"},\"sidecars\":[],\"socketReceiveBufferBytes\":102400,\"socketRequestMaxBytes\":\"_104857600\",\"socketSendBufferBytes\":102400,\"startupProbe\":{\"enabled\":false,\"failureThreshold\":15,\"initialDelaySeconds\":30,\"periodSeconds\":10,\"successThreshold\":1,\"timeoutSeconds\":1},\"superUsers\":\"User:admin\",\"terminationGracePeriodSeconds\":\"\",\"tolerations\":[],\"topologySpreadConstraints\":[],\"transactionStateLogMinIsr\":1,\"transactionStateLogReplicationFactor\":1,\"updateStrategy\":{\"rollingUpdate\":{},\"type\":\"RollingUpdate\"},\"volumePermissions\":{\"containerSecurityContext\":{\"runAsUser\":0},\"enabled\":false,\"image\":{\"digest\":\"\",\"pullPolicy\":\"IfNotPresent\",\"pullSecrets\":[],\"registry\":\"docker.io\",\"repository\":\"bitnami/bitnami-shell\",\"tag\":\"11-debian-11-r63\"},\"resources\":{\"limits\":{},\"requests\":{}}},\"zookeeper\":{\"auth\":{\"client\":{\"clientPassword\":\"\",\"clientUser\":\"\",\"enabled\":false,\"serverPasswords\":\"\",\"serverUsers\":\"\"}},\"enabled\":true,\"persistence\":{\"accessModes\":[\"ReadWriteOnce\"],\"enabled\":true,\"size\":\"8Gi\",\"storageClass\":\"\"},\"replicaCount\":1},\"zookeeperChrootPath\":\"\",\"zookeeperConnectionTimeoutMs\":6000}",
                "version": "20.0.2"
              }
            ],
            "name": "kafka",
            "namespace": "knowlg-db",
            "pass_credentials": false,
            "postrender": [],
            "recreate_pods": false,
            "render_subchart_notes": true,
            "replace": false,
            "repository": null,
            "repository_ca_file": null,
            "repository_cert_file": null,
            "repository_key_file": null,
            "repository_password": null,
            "repository_username": null,
            "reset_values": false,
            "reuse_values": false,
            "set": [],
            "set_sensitive": [],
            "skip_crds": false,
            "status": "deployed",
            "timeout": 300,
            "values": [
              "## @section Global parameters\n## Global Docker image parameters\n## Please, note that this will override the image parameters, including dependencies, configured to use the global value\n## Current available global Docker image parameters: imageRegistry, imagePullSecrets and storageClass\n\n## @param global.imageRegistry Global Docker image registry\n## @param global.imagePullSecrets Global Docker registry secret names as an array\n## @param global.storageClass Global StorageClass for Persistent Volume(s)\n##\nglobal:\n  imageRegistry: \"\"\n  ## E.g.\n  ## imagePullSecrets:\n  ##   - myRegistryKeySecretName\n  ##\n  imagePullSecrets: []\n  storageClass: \"\"\n\n## @section Common parameters\n\n## @param kubeVersion Override Kubernetes version\n##\nkubeVersion: \"\"\n## @param nameOverride String to partially override common.names.fullname\n##\nnameOverride: \"\"\n## @param fullnameOverride String to fully override common.names.fullname\n##\nfullnameOverride: \"\"\n## @param clusterDomain Default Kubernetes cluster domain\n##\nclusterDomain: cluster.local\n## @param commonLabels Labels to add to all deployed objects\n##\ncommonLabels: {}\n## @param commonAnnotations Annotations to add to all deployed objects\n##\ncommonAnnotations: {}\n## @param extraDeploy Array of extra objects to deploy with the release\n##\nextraDeploy: []\n## Enable diagnostic mode in the statefulset\n##\ndiagnosticMode:\n  ## @param diagnosticMode.enabled Enable diagnostic mode (all probes will be disabled and the command will be overridden)\n  ##\n  enabled: false\n  ## @param diagnosticMode.command Command to override all containers in the statefulset\n  ##\n  command:\n    - sleep\n  ## @param diagnosticMode.args Args to override all containers in the statefulset\n  ##\n  args:\n    - infinity\n\n## @section Kafka parameters\n\n## Bitnami Kafka image version\n## ref: https://hub.docker.com/r/bitnami/kafka/tags/\n## @param image.registry Kafka image registry\n## @param image.repository Kafka image repository\n## @param image.tag Kafka image tag (immutable tags are recommended)\n## @param image.digest Kafka image digest in the way sha256:aa.... Please note this parameter, if set, will override the tag\n## @param image.pullPolicy Kafka image pull policy\n## @param image.pullSecrets Specify docker-registry secret names as an array\n## @param image.debug Specify if debug values should be set\n##\nimage:\n  registry: docker.io\n  repository: bitnami/kafka\n  tag: 3.3.1-debian-11-r25\n  digest: \"\"\n  ## Specify a imagePullPolicy\n  ## Defaults to 'Always' if image tag is 'latest', else set to 'IfNotPresent'\n  ## ref: https://kubernetes.io/docs/user-guide/images/#pre-pulling-images\n  ##\n  pullPolicy: IfNotPresent\n  ## Optionally specify an array of imagePullSecrets.\n  ## Secrets must be manually created in the namespace.\n  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/\n  ## e.g:\n  ## pullSecrets:\n  ##   - myRegistryKeySecretName\n  ##\n  pullSecrets: []\n  ## Set to true if you would like to see extra information on logs\n  ##\n  debug: false\n## @param config Configuration file for Kafka. Auto-generated based on other parameters when not specified\n## Specify content for server.properties\n## NOTE: This will override any KAFKA_CFG_ environment variables (including those set by the chart)\n## The server.properties is auto-generated based on other parameters when this parameter is not specified\n## e.g:\n## config: |-\n##   broker.id=-1\n##   listeners=PLAINTEXT://:9092\n##   advertised.listeners=PLAINTEXT://KAFKA_IP:9092\n##   num.network.threads=3\n##   num.io.threads=8\n##   socket.send.buffer.bytes=102400\n##   socket.receive.buffer.bytes=102400\n##   socket.request.max.bytes=104857600\n##   log.dirs=/bitnami/kafka/data\n##   num.partitions=1\n##   num.recovery.threads.per.data.dir=1\n##   offsets.topic.replication.factor=1\n##   transaction.state.log.replication.factor=1\n##   transaction.state.log.min.isr=1\n##   log.flush.interval.messages=10000\n##   log.flush.interval.ms=1000\n##   log.retention.hours=168\n##   log.retention.bytes=1073741824\n##   log.segment.bytes=1073741824\n##   log.retention.check.interval.ms=300000\n##   zookeeper.connect=ZOOKEEPER_SERVICE_NAME\n##   zookeeper.connection.timeout.ms=6000\n##   group.initial.rebalance.delay.ms=0\n##\nconfig: \"\"\n## @param existingConfigmap ConfigMap with Kafka Configuration\n## NOTE: This will override `config` AND any KAFKA_CFG_ environment variables\n##\nexistingConfigmap: \"\"\n## @param log4j An optional log4j.properties file to overwrite the default of the Kafka brokers\n## An optional log4j.properties file to overwrite the default of the Kafka brokers\n## ref: https://github.com/apache/kafka/blob/trunk/config/log4j.properties\n##\nlog4j: \"\"\n## @param existingLog4jConfigMap The name of an existing ConfigMap containing a log4j.properties file\n## The name of an existing ConfigMap containing a log4j.properties file\n## NOTE: this will override `log4j`\n##\nexistingLog4jConfigMap: \"\"\n## @param heapOpts Kafka Java Heap size\n##\nheapOpts: -Xmx1024m -Xms1024m\n## @param deleteTopicEnable Switch to enable topic deletion or not\n##\ndeleteTopicEnable: false\n## @param autoCreateTopicsEnable Switch to enable auto creation of topics. Enabling auto creation of topics not recommended for production or similar environments\n##\nautoCreateTopicsEnable: true\n## @param logFlushIntervalMessages The number of messages to accept before forcing a flush of data to disk\n##\nlogFlushIntervalMessages: _10000\n## @param logFlushIntervalMs The maximum amount of time a message can sit in a log before we force a flush\n##\nlogFlushIntervalMs: 1000\n## @param logRetentionBytes A size-based retention policy for logs\n##\nlogRetentionBytes: _1073741824\n## @param logRetentionCheckIntervalMs The interval at which log segments are checked to see if they can be deleted\n##\nlogRetentionCheckIntervalMs: 300000\n## @param logRetentionHours The minimum age of a log file to be eligible for deletion due to age\n##\nlogRetentionHours: 168\n## @param logSegmentBytes The maximum size of a log segment file. When this size is reached a new log segment will be created\n##\nlogSegmentBytes: _1073741824\n## @param logsDirs A comma separated list of directories in which kafka's log data is kept\n## ref: https://kafka.apache.org/documentation/#brokerconfigs_log.dirs\nlogsDirs: /bitnami/kafka/data\n## @param maxMessageBytes The largest record batch size allowed by Kafka\n##\nmaxMessageBytes: _1000012\n## @param defaultReplicationFactor Default replication factors for automatically created topics\n##\ndefaultReplicationFactor: 1\n## @param offsetsTopicReplicationFactor The replication factor for the offsets topic\n##\noffsetsTopicReplicationFactor: 1\n## @param transactionStateLogReplicationFactor The replication factor for the transaction topic\n##\ntransactionStateLogReplicationFactor: 1\n## @param transactionStateLogMinIsr Overridden min.insync.replicas config for the transaction topic\n##\ntransactionStateLogMinIsr: 1\n## @param numIoThreads The number of threads doing disk I/O\n##\nnumIoThreads: 8\n## @param numNetworkThreads The number of threads handling network requests\n##\nnumNetworkThreads: 3\n## @param numPartitions The default number of log partitions per topic\n##\nnumPartitions: 1\n## @param numRecoveryThreadsPerDataDir The number of threads per data directory to be used for log recovery at startup and flushing at shutdown\n##\nnumRecoveryThreadsPerDataDir: 1\n## @param socketReceiveBufferBytes The receive buffer (SO_RCVBUF) used by the socket server\n##\nsocketReceiveBufferBytes: 102400\n## @param socketRequestMaxBytes The maximum size of a request that the socket server will accept (protection against OOM)\n##\nsocketRequestMaxBytes: _104857600\n## @param socketSendBufferBytes The send buffer (SO_SNDBUF) used by the socket server\n##\nsocketSendBufferBytes: 102400\n## @param zookeeperConnectionTimeoutMs Timeout in ms for connecting to ZooKeeper\n##\nzookeeperConnectionTimeoutMs: 6000\n## @param zookeeperChrootPath Path which puts data under some path in the global ZooKeeper namespace\n## ref: https://kafka.apache.org/documentation/#brokerconfigs_zookeeper.connect\n##\nzookeeperChrootPath: \"\"\n## @param authorizerClassName The Authorizer is configured by setting authorizer.class.name=kafka.security.authorizer.AclAuthorizer in server.properties\n##\nauthorizerClassName: \"\"\n## @param allowEveryoneIfNoAclFound By default, if a resource has no associated ACLs, then no one is allowed to access that resource except super users\n##\nallowEveryoneIfNoAclFound: true\n## @param superUsers You can add super users in server.properties\n##\nsuperUsers: User:admin\n## Authentication parameters\n## https://github.com/bitnami/containers/tree/main/bitnami/kafka#security\n##\nauth:\n  ## Authentication protocol for client and inter-broker communications\n  ## This table shows the security provided on each protocol:\n  ## | Method    | Authentication                | Encryption via TLS |\n  ## | plaintext | None                          | No                 |\n  ## | tls       | None                          | Yes                |\n  ## | mtls      | Yes (two-way authentication)  | Yes                |\n  ## | sasl      | Yes (via SASL)                | No                 |\n  ## | sasl_tls  | Yes (via SASL)                | Yes                |\n  ## @param auth.clientProtocol Authentication protocol for communications with clients. Allowed protocols: `plaintext`, `tls`, `mtls`, `sasl` and `sasl_tls`\n  ## @param auth.externalClientProtocol Authentication protocol for communications with external clients. Defaults to value of `auth.clientProtocol`. Allowed protocols: `plaintext`, `tls`, `mtls`, `sasl` and `sasl_tls`\n  ## @param auth.interBrokerProtocol Authentication protocol for inter-broker communications. Allowed protocols: `plaintext`, `tls`, `mtls`, `sasl` and `sasl_tls`\n  ##\n  clientProtocol: plaintext\n  # Note: empty by default for backwards compatibility reasons, find more information at\n  # https://github.com/bitnami/charts/pull/8902/\n  externalClientProtocol: \"\"\n  interBrokerProtocol: plaintext\n  ## SASL configuration\n  ##\n  sasl:\n    ## @param auth.sasl.mechanisms SASL mechanisms when either `auth.interBrokerProtocol`, `auth.clientProtocol` or `auth.externalClientProtocol` are `sasl`. Allowed types: `plain`, `scram-sha-256`, `scram-sha-512`\n    ##\n    mechanisms: plain,scram-sha-256,scram-sha-512\n    ## @param auth.sasl.interBrokerMechanism SASL mechanism for inter broker communication.\n    ##\n    interBrokerMechanism: plain\n    ## JAAS configuration for SASL authentication.\n    ##\n    jaas:\n      ## @param auth.sasl.jaas.clientUsers Kafka client user list\n      ##\n      ## clientUsers:\n      ##   - user1\n      ##   - user2\n      ##\n      clientUsers:\n        - user\n      ## @param auth.sasl.jaas.clientPasswords Kafka client passwords. This is mandatory if more than one user is specified in clientUsers\n      ##\n      ## clientPasswords:\n      ##   - password1\n      ##   - password2\"\n      ##\n      clientPasswords: []\n      ## @param auth.sasl.jaas.interBrokerUser Kafka inter broker communication user for SASL authentication\n      ##\n      interBrokerUser: admin\n      ## @param auth.sasl.jaas.interBrokerPassword Kafka inter broker communication password for SASL authentication\n      ##\n      interBrokerPassword: \"\"\n      ## @param auth.sasl.jaas.zookeeperUser Kafka ZooKeeper user for SASL authentication\n      ##\n      zookeeperUser: \"\"\n      ## @param auth.sasl.jaas.zookeeperPassword Kafka ZooKeeper password for SASL authentication\n      ##\n      zookeeperPassword: \"\"\n      ## @param auth.sasl.jaas.existingSecret Name of the existing secret containing credentials for clientUsers, interBrokerUser and zookeeperUser\n      ## Create this secret running the command below where SECRET_NAME is the name of the secret you want to create:\n      ##       kubectl create secret generic SECRET_NAME --from-literal=client-passwords=CLIENT_PASSWORD1,CLIENT_PASSWORD2 --from-literal=inter-broker-password=INTER_BROKER_PASSWORD --from-literal=zookeeper-password=ZOOKEEPER_PASSWORD\n      ##\n      existingSecret: \"\"\n  ## TLS configuration\n  ##\n  tls:\n    ## @param auth.tls.type Format to use for TLS certificates. Allowed types: `jks` and `pem`\n    ##\n    type: jks\n    ## @param auth.tls.pemChainIncluded Flag to denote that the Certificate Authority (CA) certificates are bundled with the endpoint cert.\n    ## Certificates must be in proper order, where the top certificate is the leaf and the bottom certificate is the top-most intermediate CA.\n    ##\n    pemChainIncluded: false\n    ## @param auth.tls.existingSecrets Array existing secrets containing the TLS certificates for the Kafka brokers\n    ## When using 'jks' format for certificates, each secret should contain a truststore and a keystore.\n    ## Create these secrets following the steps below:\n    ## 1) Generate your truststore and keystore files. Helpful script: https://raw.githubusercontent.com/confluentinc/confluent-platform-security-tools/master/kafka-generate-ssl.sh\n    ## 2) Rename your truststore to `kafka.truststore.jks`.\n    ## 3) Rename your keystores to `kafka-X.keystore.jks` where X is the ID of each Kafka broker.\n    ## 4) Run the command below one time per broker to create its associated secret (SECRET_NAME_X is the name of the secret you want to create):\n    ##       kubectl create secret generic SECRET_NAME_0 --from-file=kafka.truststore.jks=./kafka.truststore.jks --from-file=kafka.keystore.jks=./kafka-0.keystore.jks\n    ##       kubectl create secret generic SECRET_NAME_1 --from-file=kafka.truststore.jks=./kafka.truststore.jks --from-file=kafka.keystore.jks=./kafka-1.keystore.jks\n    ##       ...\n    ##\n    ## When using 'pem' format for certificates, each secret should contain a public CA certificate, a public certificate and one private key.\n    ## Create these secrets following the steps below:\n    ## 1) Create a certificate key and signing request per Kafka broker, and sign the signing request with your CA\n    ## 2) Rename your CA file to `kafka.ca.crt`.\n    ## 3) Rename your certificates to `kafka-X.tls.crt` where X is the ID of each Kafka broker.\n    ## 3) Rename your keys to `kafka-X.tls.key` where X is the ID of each Kafka broker.\n    ## 4) Run the command below one time per broker to create its associated secret (SECRET_NAME_X is the name of the secret you want to create):\n    ##       kubectl create secret generic SECRET_NAME_0 --from-file=ca.crt=./kafka.ca.crt --from-file=tls.crt=./kafka-0.tls.crt --from-file=tls.key=./kafka-0.tls.key\n    ##       kubectl create secret generic SECRET_NAME_1 --from-file=ca.crt=./kafka.ca.crt --from-file=tls.crt=./kafka-1.tls.crt --from-file=tls.key=./kafka-1.tls.key\n    ##       ...\n    ##\n    existingSecrets: []\n    ## @param auth.tls.autoGenerated Generate automatically self-signed TLS certificates for Kafka brokers. Currently only supported if `auth.tls.type` is `pem`\n    ## Note: ignored when using 'jks' format or `auth.tls.existingSecrets` is not empty\n    ##\n    autoGenerated: false\n    ## @param auth.tls.password Password to access the JKS files or PEM key when they are password-protected.\n    ## Note: ignored when using 'existingSecret'.\n    ##\n    password: \"\"\n    ## @param auth.tls.existingSecret Name of the secret containing the password to access the JKS files or PEM key when they are password-protected. (`key`: `password`)\n    ##\n    existingSecret: \"\"\n    ## @param auth.tls.jksTruststoreSecret Name of the existing secret containing your truststore if truststore not existing or different from the ones in the `auth.tls.existingSecrets`\n    ## Note: ignored when using 'pem' format for certificates.\n    ##\n    jksTruststoreSecret: \"\"\n    ## @param auth.tls.jksKeystoreSAN The secret key from the `auth.tls.existingSecrets` containing the keystore with a SAN certificate\n    ## The SAN certificate in it should be issued with Subject Alternative Names for all headless services:\n    ##  - kafka-0.kafka-headless.kafka.svc.cluster.local\n    ##  - kafka-1.kafka-headless.kafka.svc.cluster.local\n    ##  - kafka-2.kafka-headless.kafka.svc.cluster.local\n    ## Note: ignored when using 'pem' format for certificates.\n    ##\n    jksKeystoreSAN: \"\"\n    ## @param auth.tls.jksTruststore The secret key from the `auth.tls.existingSecrets` or `auth.tls.jksTruststoreSecret` containing the truststore\n    ## Note: ignored when using 'pem' format for certificates.\n    ##\n    jksTruststore: \"\"\n    ## @param auth.tls.endpointIdentificationAlgorithm The endpoint identification algorithm to validate server hostname using server certificate\n    ## Disable server host name verification by setting it to an empty string.\n    ## ref: https://docs.confluent.io/current/kafka/authentication_ssl.html#optional-settings\n    ##\n    endpointIdentificationAlgorithm: https\n  ## Zookeeper client configuration for kafka brokers\n  ##\n  zookeeper:\n    ## TLS configuration\n    ##\n    tls:\n      ## @param auth.zookeeper.tls.enabled Enable TLS for Zookeeper client connections.\n      ##\n      enabled: false\n      ## @param auth.zookeeper.tls.type Format to use for TLS certificates. Allowed types: `jks` and `pem`.\n      ##\n      type: jks\n      ## @param auth.zookeeper.tls.verifyHostname Hostname validation.\n      ##\n      verifyHostname: true\n      ## @param auth.zookeeper.tls.existingSecret Name of the existing secret containing the TLS certificates for ZooKeeper client communications.\n      ##\n      existingSecret: \"\"\n      ## @param auth.zookeeper.tls.existingSecretKeystoreKey The secret key from the  auth.zookeeper.tls.existingSecret containing the Keystore.\n      ##\n      existingSecretKeystoreKey: zookeeper.keystore.jks\n      ## @param auth.zookeeper.tls.existingSecretTruststoreKey The secret key from the auth.zookeeper.tls.existingSecret containing the Truststore.\n      ##\n      existingSecretTruststoreKey: zookeeper.truststore.jks\n      ## @param auth.zookeeper.tls.passwordsSecret Existing secret containing Keystore and Truststore passwords.\n      ##\n      passwordsSecret: \"\"\n      ## @param auth.zookeeper.tls.passwordsSecretKeystoreKey The secret key from the auth.zookeeper.tls.passwordsSecret containing the password for the Keystore.\n      ##\n      passwordsSecretKeystoreKey: keystore-password\n      ## @param auth.zookeeper.tls.passwordsSecretTruststoreKey The secret key from the auth.zookeeper.tls.passwordsSecret containing the password for the Truststore.\n      ##\n      passwordsSecretTruststoreKey: truststore-password\n## @param listeners The address(es) the socket server listens on. Auto-calculated it's set to an empty array\n## When it's set to an empty array, the listeners will be configured\n## based on the authentication protocols (auth.clientProtocol, auth.externalClientProtocol and auth.interBrokerProtocol parameters)\n##\nlisteners: []\n## @param advertisedListeners The address(es) (hostname:port) the broker will advertise to producers and consumers. Auto-calculated it's set to an empty array\n## When it's set to an empty array, the advertised listeners will be configured\n## based on the authentication protocols (auth.clientProtocol, auth.externalClientProtocol and auth.interBrokerProtocol parameters)\n##\nadvertisedListeners: []\n## @param listenerSecurityProtocolMap The protocol-\u003elistener mapping. Auto-calculated it's set to nil\n## When it's nil, the listeners will be configured based on the authentication protocols (auth.clientProtocol, auth.externalClientProtocol and auth.interBrokerProtocol parameters)\n##\nlistenerSecurityProtocolMap: \"\"\n## @param allowPlaintextListener Allow to use the PLAINTEXT listener\n##\nallowPlaintextListener: true\n## @param interBrokerListenerName The listener that the brokers should communicate on\n##\ninterBrokerListenerName: INTERNAL\n## @param command Override Kafka container command\n##\ncommand:\n  - /scripts/setup.sh\n## @param args Override Kafka container arguments\n##\nargs: []\n## @param extraEnvVars Extra environment variables to add to Kafka pods\n## ref: https://github.com/bitnami/containers/tree/main/bitnami/kafka#configuration\n## e.g:\n## extraEnvVars:\n##   - name: KAFKA_CFG_BACKGROUND_THREADS\n##     value: \"10\"\n##\nextraEnvVars: []\n## @param extraEnvVarsCM ConfigMap with extra environment variables\n##\nextraEnvVarsCM: \"\"\n## @param extraEnvVarsSecret Secret with extra environment variables\n##\nextraEnvVarsSecret: \"\"\n\n## @section Statefulset parameters\n\n## @param replicaCount Number of Kafka nodes\n##\nreplicaCount: 1\n## @param minBrokerId Minimal broker.id value, nodes increment their `broker.id` respectively\n## Brokers increment their ID starting at this minimal value.\n## E.g., with `minBrokerId=100` and 3 nodes, IDs will be 100, 101, 102 for brokers 0, 1, and 2, respectively.\n##\nminBrokerId: 0\n## @param brokerRackAssignment Set Broker Assignment for multi tenant environment Allowed values: `aws-az`\n## ref: https://cwiki.apache.org/confluence/display/KAFKA/KIP-392%3A+Allow+consumers+to+fetch+from+closest+replica\n##\nbrokerRackAssignment: \"\"\n## @param containerPorts.client Kafka client container port\n## @param containerPorts.internal Kafka inter-broker container port\n## @param containerPorts.external Kafka external container port\n##\ncontainerPorts:\n  client: 9092\n  internal: 9093\n  external: 9094\n## Configure extra options for Kafka containers' liveness, readiness and startup probes\n## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/#configure-probes\n## @param livenessProbe.enabled Enable livenessProbe on Kafka containers\n## @param livenessProbe.initialDelaySeconds Initial delay seconds for livenessProbe\n## @param livenessProbe.periodSeconds Period seconds for livenessProbe\n## @param livenessProbe.timeoutSeconds Timeout seconds for livenessProbe\n## @param livenessProbe.failureThreshold Failure threshold for livenessProbe\n## @param livenessProbe.successThreshold Success threshold for livenessProbe\n##\nlivenessProbe:\n  enabled: true\n  initialDelaySeconds: 10\n  timeoutSeconds: 5\n  failureThreshold: 3\n  periodSeconds: 10\n  successThreshold: 1\n## @param readinessProbe.enabled Enable readinessProbe on Kafka containers\n## @param readinessProbe.initialDelaySeconds Initial delay seconds for readinessProbe\n## @param readinessProbe.periodSeconds Period seconds for readinessProbe\n## @param readinessProbe.timeoutSeconds Timeout seconds for readinessProbe\n## @param readinessProbe.failureThreshold Failure threshold for readinessProbe\n## @param readinessProbe.successThreshold Success threshold for readinessProbe\n##\nreadinessProbe:\n  enabled: true\n  initialDelaySeconds: 5\n  failureThreshold: 6\n  timeoutSeconds: 5\n  periodSeconds: 10\n  successThreshold: 1\n## @param startupProbe.enabled Enable startupProbe on Kafka containers\n## @param startupProbe.initialDelaySeconds Initial delay seconds for startupProbe\n## @param startupProbe.periodSeconds Period seconds for startupProbe\n## @param startupProbe.timeoutSeconds Timeout seconds for startupProbe\n## @param startupProbe.failureThreshold Failure threshold for startupProbe\n## @param startupProbe.successThreshold Success threshold for startupProbe\n##\nstartupProbe:\n  enabled: false\n  initialDelaySeconds: 30\n  periodSeconds: 10\n  timeoutSeconds: 1\n  failureThreshold: 15\n  successThreshold: 1\n## @param customLivenessProbe Custom livenessProbe that overrides the default one\n##\ncustomLivenessProbe: {}\n## @param customReadinessProbe Custom readinessProbe that overrides the default one\n##\ncustomReadinessProbe: {}\n## @param customStartupProbe Custom startupProbe that overrides the default one\n##\ncustomStartupProbe: {}\n## @param lifecycleHooks lifecycleHooks for the Kafka container to automate configuration before or after startup\n##\nlifecycleHooks: {}\n## Kafka resource requests and limits\n## ref: https://kubernetes.io/docs/user-guide/compute-resources/\n## @param resources.limits The resources limits for the container\n## @param resources.requests The requested resources for the container\n##\nresources:\n  limits: {}\n  requests: {}\n## Kafka pods' Security Context\n## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-pod\n## @param podSecurityContext.enabled Enable security context for the pods\n## @param podSecurityContext.fsGroup Set Kafka pod's Security Context fsGroup\n##\npodSecurityContext:\n  enabled: true\n  fsGroup: 1001\n## Kafka containers' Security Context\n## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-container\n## @param containerSecurityContext.enabled Enable Kafka containers' Security Context\n## @param containerSecurityContext.runAsUser Set Kafka containers' Security Context runAsUser\n## @param containerSecurityContext.runAsNonRoot Set Kafka containers' Security Context runAsNonRoot\n## @param containerSecurityContext.allowPrivilegeEscalation Force the child process to be run as nonprivilege\n## e.g:\n##   containerSecurityContext:\n##     enabled: true\n##     capabilities:\n##       drop: [\"NET_RAW\"]\n##     readOnlyRootFilesystem: true\n##\ncontainerSecurityContext:\n  enabled: true\n  runAsUser: 1001\n  runAsNonRoot: true\n  allowPrivilegeEscalation: false\n## @param hostAliases Kafka pods host aliases\n## https://kubernetes.io/docs/concepts/services-networking/add-entries-to-pod-etc-hosts-with-host-aliases/\n##\nhostAliases: []\n## @param hostNetwork Specify if host network should be enabled for Kafka pods\n##\nhostNetwork: false\n## @param hostIPC Specify if host IPC should be enabled for Kafka pods\n##\nhostIPC: false\n## @param podLabels Extra labels for Kafka pods\n## Ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/\n##\npodLabels: {}\n## @param podAnnotations Extra annotations for Kafka pods\n## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/\n##\npodAnnotations: {}\n## @param podAffinityPreset Pod affinity preset. Ignored if `affinity` is set. Allowed values: `soft` or `hard`\n## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity\n##\npodAffinityPreset: \"\"\n## @param podAntiAffinityPreset Pod anti-affinity preset. Ignored if `affinity` is set. Allowed values: `soft` or `hard`\n## Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity\n##\npodAntiAffinityPreset: soft\n## Node affinity preset\n## Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity\n##\nnodeAffinityPreset:\n  ## @param nodeAffinityPreset.type Node affinity preset type. Ignored if `affinity` is set. Allowed values: `soft` or `hard`\n  ##\n  type: \"\"\n  ## @param nodeAffinityPreset.key Node label key to match Ignored if `affinity` is set.\n  ## E.g.\n  ## key: \"kubernetes.io/e2e-az-name\"\n  ##\n  key: \"\"\n  ## @param nodeAffinityPreset.values Node label values to match. Ignored if `affinity` is set.\n  ## E.g.\n  ## values:\n  ##   - e2e-az1\n  ##   - e2e-az2\n  ##\n  values: []\n## @param affinity Affinity for pod assignment\n## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity\n## Note: podAffinityPreset, podAntiAffinityPreset, and  nodeAffinityPreset will be ignored when it's set\n##\naffinity: {}\n## @param nodeSelector Node labels for pod assignment\n## Ref: https://kubernetes.io/docs/user-guide/node-selection/\n##\nnodeSelector: {}\n## @param tolerations Tolerations for pod assignment\n## Ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/\n##\ntolerations: []\n## @param topologySpreadConstraints Topology Spread Constraints for pod assignment spread across your cluster among failure-domains. Evaluated as a template\n## Ref: https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/#spread-constraints-for-pods\n##\ntopologySpreadConstraints: []\n## @param terminationGracePeriodSeconds Seconds the pod needs to gracefully terminate\n## ref: https://kubernetes.io/docs/concepts/containers/container-lifecycle-hooks/#hook-handler-execution\n##\nterminationGracePeriodSeconds: \"\"\n## @param podManagementPolicy StatefulSet controller supports relax its ordering guarantees while preserving its uniqueness and identity guarantees. There are two valid pod management policies: OrderedReady and Parallel\n## ref: https://kubernetes.io/docs/tutorials/stateful-application/basic-stateful-set/#pod-management-policy\n##\npodManagementPolicy: Parallel\n## @param priorityClassName Name of the existing priority class to be used by kafka pods\n## Ref: https://kubernetes.io/docs/concepts/configuration/pod-priority-preemption/\n##\npriorityClassName: \"\"\n## @param schedulerName Name of the k8s scheduler (other than default)\n## ref: https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/\n##\nschedulerName: \"\"\n## @param updateStrategy.type Kafka statefulset strategy type\n## @param updateStrategy.rollingUpdate Kafka statefulset rolling update configuration parameters\n## ref: https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/#update-strategies\n##\nupdateStrategy:\n  type: RollingUpdate\n  rollingUpdate: {}\n## @param extraVolumes Optionally specify extra list of additional volumes for the Kafka pod(s)\n## e.g:\n## extraVolumes:\n##   - name: kafka-jaas\n##     secret:\n##       secretName: kafka-jaas\n##\nextraVolumes: []\n## @param extraVolumeMounts Optionally specify extra list of additional volumeMounts for the Kafka container(s)\n## extraVolumeMounts:\n##   - name: kafka-jaas\n##     mountPath: /bitnami/kafka/config/kafka_jaas.conf\n##     subPath: kafka_jaas.conf\n##\nextraVolumeMounts: []\n## @param sidecars Add additional sidecar containers to the Kafka pod(s)\n## e.g:\n## sidecars:\n##   - name: your-image-name\n##     image: your-image\n##     imagePullPolicy: Always\n##     ports:\n##       - name: portname\n##         containerPort: 1234\n##\nsidecars: []\n## @param initContainers Add additional Add init containers to the Kafka pod(s)\n## e.g:\n## initContainers:\n##   - name: your-image-name\n##     image: your-image\n##     imagePullPolicy: Always\n##     ports:\n##       - name: portname\n##         containerPort: 1234\n##\ninitContainers: []\n## Kafka Pod Disruption Budget\n## ref: https://kubernetes.io/docs/concepts/workloads/pods/disruptions/\n## @param pdb.create Deploy a pdb object for the Kafka pod\n## @param pdb.minAvailable Maximum number/percentage of unavailable Kafka replicas\n## @param pdb.maxUnavailable Maximum number/percentage of unavailable Kafka replicas\n##\npdb:\n  create: false\n  minAvailable: \"\"\n  maxUnavailable: 1\n\n## @section Traffic Exposure parameters\n\n## Service parameters\n##\nservice:\n  ## @param service.type Kubernetes Service type\n  ##\n  type: ClusterIP\n  ## @param service.ports.client Kafka svc port for client connections\n  ## @param service.ports.internal Kafka svc port for inter-broker connections\n  ## @param service.ports.external Kafka svc port for external connections\n  ##\n  ports:\n    client: 9092\n    internal: 9093\n    external: 9094\n  ## @param service.nodePorts.client Node port for the Kafka client connections\n  ## @param service.nodePorts.external Node port for the Kafka external connections\n  ## NOTE: choose port between \u003c30000-32767\u003e\n  ##\n  nodePorts:\n    client: \"\"\n    external: \"\"\n  ## @param service.sessionAffinity Control where client requests go, to the same pod or round-robin\n  ## Values: ClientIP or None\n  ## ref: https://kubernetes.io/docs/user-guide/services/\n  ##\n  sessionAffinity: None\n  ## @param service.sessionAffinityConfig Additional settings for the sessionAffinity\n  ## sessionAffinityConfig:\n  ##   clientIP:\n  ##     timeoutSeconds: 300\n  ##\n  sessionAffinityConfig: {}\n  ## @param service.clusterIP Kafka service Cluster IP\n  ## e.g.:\n  ## clusterIP: None\n  ##\n  clusterIP: \"\"\n  ## @param service.loadBalancerIP Kafka service Load Balancer IP\n  ## ref: https://kubernetes.io/docs/user-guide/services/#type-loadbalancer\n  ##\n  loadBalancerIP: \"\"\n  ## @param service.loadBalancerSourceRanges Kafka service Load Balancer sources\n  ## ref: https://kubernetes.io/docs/tasks/access-application-cluster/configure-cloud-provider-firewall/#restrict-access-for-loadbalancer-service\n  ## e.g:\n  ## loadBalancerSourceRanges:\n  ##   - 10.10.10.0/24\n  ##\n  loadBalancerSourceRanges: []\n  ## @param service.externalTrafficPolicy Kafka service external traffic policy\n  ## ref https://kubernetes.io/docs/tasks/access-application-cluster/create-external-load-balancer/#preserving-the-client-source-ip\n  ##\n  externalTrafficPolicy: Cluster\n  ## @param service.annotations Additional custom annotations for Kafka service\n  ##\n  annotations: {}\n  ## Headless service properties\n  ##\n  headless:\n    ## @param service.headless.publishNotReadyAddresses Indicates that any agent which deals with endpoints for this Service should disregard any indications of ready/not-ready\n    ## ref: https://kubernetes.io/docs/reference/kubernetes-api/service-resources/service-v1/\n    publishNotReadyAddresses: false\n    ## @param service.headless.annotations Annotations for the headless service.\n    ##\n    annotations: {}\n    ## @param service.headless.labels Labels for the headless service.\n    ##\n    labels: {}\n  ## @param service.extraPorts Extra ports to expose in the Kafka service (normally used with the `sidecar` value)\n  ##\n  extraPorts: []\n## External Access to Kafka brokers configuration\n##\nexternalAccess:\n  ## @param externalAccess.enabled Enable Kubernetes external cluster access to Kafka brokers\n  ##\n  enabled: false\n  ## External IPs auto-discovery configuration\n  ## An init container is used to auto-detect LB IPs or node ports by querying the K8s API\n  ## Note: RBAC might be required\n  ##\n  autoDiscovery:\n    ## @param externalAccess.autoDiscovery.enabled Enable using an init container to auto-detect external IPs/ports by querying the K8s API\n    ##\n    enabled: false\n    ## Bitnami Kubectl image\n    ## ref: https://hub.docker.com/r/bitnami/kubectl/tags/\n    ## @param externalAccess.autoDiscovery.image.registry Init container auto-discovery image registry\n    ## @param externalAccess.autoDiscovery.image.repository Init container auto-discovery image repository\n    ## @param externalAccess.autoDiscovery.image.tag Init container auto-discovery image tag (immutable tags are recommended)\n    ## @param externalAccess.autoDiscovery.image.digest Petete image digest in the way sha256:aa.... Please note this parameter, if set, will override the tag\n    ## @param externalAccess.autoDiscovery.image.pullPolicy Init container auto-discovery image pull policy\n    ## @param externalAccess.autoDiscovery.image.pullSecrets Init container auto-discovery image pull secrets\n    ##\n    image:\n      registry: docker.io\n      repository: bitnami/kubectl\n      tag: 1.25.5-debian-11-r2\n      digest: \"\"\n      ## Specify a imagePullPolicy\n      ## Defaults to 'Always' if image tag is 'latest', else set to 'IfNotPresent'\n      ## ref: https://kubernetes.io/docs/user-guide/images/#pre-pulling-images\n      ##\n      pullPolicy: IfNotPresent\n      ## Optionally specify an array of imagePullSecrets (secrets must be manually created in the namespace)\n      ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/\n      ## e.g:\n      ## pullSecrets:\n      ##   - myRegistryKeySecretName\n      ##\n      pullSecrets: []\n    ## Init Container resource requests and limits\n    ## ref: https://kubernetes.io/docs/user-guide/compute-resources/\n    ## @param externalAccess.autoDiscovery.resources.limits The resources limits for the auto-discovery init container\n    ## @param externalAccess.autoDiscovery.resources.requests The requested resources for the auto-discovery init container\n    ##\n    resources:\n      limits: {}\n      requests: {}\n  ## Parameters to configure K8s service(s) used to externally access Kafka brokers\n  ## Note: A new service per broker will be created\n  ##\n  service:\n    ## @param externalAccess.service.type Kubernetes Service type for external access. It can be NodePort, LoadBalancer or ClusterIP\n    ##\n    type: LoadBalancer\n    ## @param externalAccess.service.ports.external Kafka port used for external access when service type is LoadBalancer\n    ##\n    ports:\n      external: 9094\n    ## @param externalAccess.service.loadBalancerIPs Array of load balancer IPs for each Kafka broker. Length must be the same as replicaCount\n    ## e.g:\n    ## loadBalancerIPs:\n    ##   - X.X.X.X\n    ##   - Y.Y.Y.Y\n    ##\n    loadBalancerIPs: []\n    ## @param externalAccess.service.loadBalancerNames Array of load balancer Names for each Kafka broker. Length must be the same as replicaCount\n    ## e.g:\n    ## loadBalancerNames:\n    ##   - broker1.external.example.com\n    ##   - broker2.external.example.com\n    ##\n    loadBalancerNames: []\n    ## @param externalAccess.service.loadBalancerAnnotations Array of load balancer annotations for each Kafka broker. Length must be the same as replicaCount\n    ## e.g:\n    ## loadBalancerAnnotations:\n    ##   - external-dns.alpha.kubernetes.io/hostname: broker1.external.example.com.\n    ##   - external-dns.alpha.kubernetes.io/hostname: broker2.external.example.com.\n    ##\n    loadBalancerAnnotations: []\n    ## @param externalAccess.service.loadBalancerSourceRanges Address(es) that are allowed when service is LoadBalancer\n    ## ref: https://kubernetes.io/docs/tasks/access-application-cluster/configure-cloud-provider-firewall/#restrict-access-for-loadbalancer-service\n    ## e.g:\n    ## loadBalancerSourceRanges:\n    ## - 10.10.10.0/24\n    ##\n    loadBalancerSourceRanges: []\n    ## @param externalAccess.service.nodePorts Array of node ports used for each Kafka broker. Length must be the same as replicaCount\n    ## e.g:\n    ## nodePorts:\n    ##   - 30001\n    ##   - 30002\n    ##\n    nodePorts: []\n    ## @param externalAccess.service.useHostIPs Use service host IPs to configure Kafka external listener when service type is NodePort\n    ##\n    useHostIPs: false\n    ## @param externalAccess.service.usePodIPs using the MY_POD_IP address for external access.\n    ##\n    usePodIPs: false\n    ## @param externalAccess.service.domain Domain or external ip used to configure Kafka external listener when service type is NodePort or ClusterIP\n    ## NodePort: If not specified, the container will try to get the kubernetes node external IP\n    ## ClusterIP: Must be specified, ingress IP or domain where tcp for external ports is configured\n    ##\n    domain: \"\"\n    ## @param externalAccess.service.publishNotReadyAddresses Indicates that any agent which deals with endpoints for this Service should disregard any indications of ready/not-ready\n    ## ref: https://kubernetes.io/docs/reference/kubernetes-api/service-resources/service-v1/\n    publishNotReadyAddresses: false\n    ## @param externalAccess.service.labels Service labels for external access\n    ##\n    labels: {}\n    ## @param externalAccess.service.annotations Service annotations for external access\n    ##\n    annotations: {}\n    ## @param externalAccess.service.extraPorts Extra ports to expose in the Kafka external service\n    ##\n    extraPorts: []\n## Network policies\n## Ref: https://kubernetes.io/docs/concepts/services-networking/network-policies/\n##\nnetworkPolicy:\n  ## @param networkPolicy.enabled Specifies whether a NetworkPolicy should be created\n  ##\n  enabled: false\n  ## @param networkPolicy.allowExternal Don't require client label for connections\n  ## When set to false, only pods with the correct client label will have network access to the port Kafka is\n  ## listening on. When true, zookeeper accept connections from any source (with the correct destination port).\n  ##\n  allowExternal: true\n  ## @param networkPolicy.explicitNamespacesSelector A Kubernetes LabelSelector to explicitly select namespaces from which traffic could be allowed\n  ## If explicitNamespacesSelector is missing or set to {}, only client Pods that are in the networkPolicy's namespace\n  ## and that match other criteria, the ones that have the good label, can reach the kafka.\n  ## But sometimes, we want the kafka to be accessible to clients from other namespaces, in this case, we can use this\n  ## LabelSelector to select these namespaces, note that the networkPolicy's namespace should also be explicitly added.\n  ##\n  ## e.g:\n  ## explicitNamespacesSelector:\n  ##   matchLabels:\n  ##     role: frontend\n  ##   matchExpressions:\n  ##    - {key: role, operator: In, values: [frontend]}\n  ##\n  explicitNamespacesSelector: {}\n  ## @param networkPolicy.externalAccess.from customize the from section for External Access on tcp-external port\n  ## e.g:\n  ## - ipBlock:\n  ##    cidr: 172.9.0.0/16\n  ##    except:\n  ##    - 172.9.1.0/24\n  ##\n  externalAccess:\n    from: []\n  ## @param networkPolicy.egressRules.customRules [object] Custom network policy rule\n  ##\n  egressRules:\n    ## Additional custom egress rules\n    ## e.g:\n    ## customRules:\n    ##   - to:\n    ##       - namespaceSelector:\n    ##           matchLabels:\n    ##             label: example\n    customRules: []\n\n## @section Persistence parameters\n\n## Enable persistence using Persistent Volume Claims\n## ref: https://kubernetes.io/docs/user-guide/persistent-volumes/\n##\npersistence:\n  ## @param persistence.enabled Enable Kafka data persistence using PVC, note that ZooKeeper persistence is unaffected\n  ##\n  enabled: true\n  ## @param persistence.existingClaim A manually managed Persistent Volume and Claim\n  ## If defined, PVC must be created manually before volume will be bound\n  ## The value is evaluated as a template\n  ##\n  existingClaim: \"\"\n  ## @param persistence.storageClass PVC Storage Class for Kafka data volume\n  ## If defined, storageClassName: \u003cstorageClass\u003e\n  ## If set to \"-\", storageClassName: \"\", which disables dynamic provisioning\n  ## If undefined (the default) or set to null, no storageClassName spec is\n  ## set, choosing the default provisioner.\n  ##\n  storageClass: \"\"\n  ## @param persistence.accessModes Persistent Volume Access Modes\n  ##\n  accessModes:\n    - ReadWriteOnce\n  ## @param persistence.size PVC Storage Request for Kafka data volume\n  ##\n  size: 8Gi\n  ## @param persistence.annotations Annotations for the PVC\n  ##\n  annotations: {}\n  ## @param persistence.labels Labels for the PVC\n  ##\n  labels: {}\n  ## @param persistence.selector Selector to match an existing Persistent Volume for Kafka data PVC. If set, the PVC can't have a PV dynamically provisioned for it\n  ## selector:\n  ##   matchLabels:\n  ##     app: my-app\n  ##\n  selector: {}\n  ## @param persistence.mountPath Mount path of the Kafka data volume\n  ##\n  mountPath: /bitnami/kafka\n## Log Persistence parameters\n##\nlogPersistence:\n  ## @param logPersistence.enabled Enable Kafka logs persistence using PVC, note that ZooKeeper persistence is unaffected\n  ##\n  enabled: false\n  ## @param logPersistence.existingClaim A manually managed Persistent Volume and Claim\n  ## If defined, PVC must be created manually before volume will be bound\n  ## The value is evaluated as a template\n  ##\n  existingClaim: \"\"\n  ## @param logPersistence.storageClass PVC Storage Class for Kafka logs volume\n  ## If defined, storageClassName: \u003cstorageClass\u003e\n  ## If set to \"-\", storageClassName: \"\", which disables dynamic provisioning\n  ## If undefined (the default) or set to null, no storageClassName spec is\n  ## set, choosing the default provisioner.\n  ##\n  storageClass: \"\"\n  ## @param logPersistence.accessModes Persistent Volume Access Modes\n  ##\n  accessModes:\n    - ReadWriteOnce\n  ## @param logPersistence.size PVC Storage Request for Kafka logs volume\n  ##\n  size: 8Gi\n  ## @param logPersistence.annotations Annotations for the PVC\n  ##\n  annotations: {}\n  ## @param logPersistence.selector Selector to match an existing Persistent Volume for Kafka log data PVC. If set, the PVC can't have a PV dynamically provisioned for it\n  ## selector:\n  ##   matchLabels:\n  ##     app: my-app\n  ##\n  selector: {}\n  ## @param logPersistence.mountPath Mount path of the Kafka logs volume\n  ##\n  mountPath: /opt/bitnami/kafka/logs\n\n## @section Volume Permissions parameters\n##\n\n## Init containers parameters:\n## volumePermissions: Change the owner and group of the persistent volume(s) mountpoint(s) to 'runAsUser:fsGroup' on each node\n##\nvolumePermissions:\n  ## @param volumePermissions.enabled Enable init container that changes the owner and group of the persistent volume\n  ##\n  enabled: false\n  ## @param volumePermissions.image.registry Init container volume-permissions image registry\n  ## @param volumePermissions.image.repository Init container volume-permissions image repository\n  ## @param volumePermissions.image.tag Init container volume-permissions image tag (immutable tags are recommended)\n  ## @param volumePermissions.image.digest Init container volume-permissions image digest in the way sha256:aa.... Please note this parameter, if set, will override the tag\n  ## @param volumePermissions.image.pullPolicy Init container volume-permissions image pull policy\n  ## @param volumePermissions.image.pullSecrets Init container volume-permissions image pull secrets\n  ##\n  image:\n    registry: docker.io\n    repository: bitnami/bitnami-shell\n    tag: 11-debian-11-r63\n    digest: \"\"\n    pullPolicy: IfNotPresent\n    ## Optionally specify an array of imagePullSecrets.\n    ## Secrets must be manually created in the namespace.\n    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/\n    ## Example:\n    ## pullSecrets:\n    ##   - myRegistryKeySecretName\n    ##\n    pullSecrets: []\n  ## Init container resource requests and limits\n  ## ref: https://kubernetes.io/docs/user-guide/compute-resources/\n  ## @param volumePermissions.resources.limits Init container volume-permissions resource limits\n  ## @param volumePermissions.resources.requests Init container volume-permissions resource requests\n  ##\n  resources:\n    limits: {}\n    requests: {}\n  ## Init container' Security Context\n  ## Note: the chown of the data folder is done to containerSecurityContext.runAsUser\n  ## and not the below volumePermissions.containerSecurityContext.runAsUser\n  ## @param volumePermissions.containerSecurityContext.runAsUser User ID for the init container\n  ##\n  containerSecurityContext:\n    runAsUser: 0\n\n## @section Other Parameters\n\n## ServiceAccount for Kafka\n## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/\n##\nserviceAccount:\n  ## @param serviceAccount.create Enable creation of ServiceAccount for Kafka pods\n  ##\n  create: true\n  ## @param serviceAccount.name The name of the service account to use. If not set and `create` is `true`, a name is generated\n  ## If not set and create is true, a name is generated using the kafka.serviceAccountName template\n  ##\n  name: \"\"\n  ## @param serviceAccount.automountServiceAccountToken Allows auto mount of ServiceAccountToken on the serviceAccount created\n  ## Can be set to false if pods using this serviceAccount do not need to use K8s API\n  ##\n  automountServiceAccountToken: true\n  ## @param serviceAccount.annotations Additional custom annotations for the ServiceAccount\n  ##\n  annotations: {}\n## Role Based Access Control\n## ref: https://kubernetes.io/docs/admin/authorization/rbac/\n##\nrbac:\n  ## @param rbac.create Whether to create \u0026 use RBAC resources or not\n  ## binding Kafka ServiceAccount to a role\n  ## that allows Kafka pods querying the K8s API\n  ##\n  create: false\n\n## @section Metrics parameters\n\n## Prometheus Exporters / Metrics\n##\nmetrics:\n  ## Prometheus Kafka exporter: exposes complimentary metrics to JMX exporter\n  ##\n  kafka:\n    ## @param metrics.kafka.enabled Whether or not to create a standalone Kafka exporter to expose Kafka metrics\n    ##\n    enabled: false\n    ## Bitnami Kafka exporter image\n    ## ref: https://hub.docker.com/r/bitnami/kafka-exporter/tags/\n    ## @param metrics.kafka.image.registry Kafka exporter image registry\n    ## @param metrics.kafka.image.repository Kafka exporter image repository\n    ## @param metrics.kafka.image.tag Kafka exporter image tag (immutable tags are recommended)\n    ## @param metrics.kafka.image.digest Kafka exporter image digest in the way sha256:aa.... Please note this parameter, if set, will override the tag\n    ## @param metrics.kafka.image.pullPolicy Kafka exporter image pull policy\n    ## @param metrics.kafka.image.pullSecrets Specify docker-registry secret names as an array\n    ##\n    image:\n      registry: docker.io\n      repository: bitnami/kafka-exporter\n      tag: 1.6.0-debian-11-r40\n      digest: \"\"\n      ## Specify a imagePullPolicy\n      ## Defaults to 'Always' if image tag is 'latest', else set to 'IfNotPresent'\n      ## ref: https://kubernetes.io/docs/user-guide/images/#pre-pulling-images\n      ##\n      pullPolicy: IfNotPresent\n      ## Optionally specify an array of imagePullSecrets (secrets must be manually created in the namespace)\n      ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/\n      ## e.g:\n      ## pullSecrets:\n      ##   - myRegistryKeySecretName\n      ##\n      pullSecrets: []\n\n    ## @param metrics.kafka.certificatesSecret Name of the existing secret containing the optional certificate and key files\n    ## for Kafka exporter client authentication\n    ##\n    certificatesSecret: \"\"\n    ## @param metrics.kafka.tlsCert The secret key from the certificatesSecret if 'client-cert' key different from the default (cert-file)\n    ##\n    tlsCert: cert-file\n    ## @param metrics.kafka.tlsKey The secret key from the certificatesSecret if 'client-key' key different from the default (key-file)\n    ##\n    tlsKey: key-file\n    ## @param metrics.kafka.tlsCaSecret Name of the existing secret containing the optional ca certificate for Kafka exporter client authentication\n    ##\n    tlsCaSecret: \"\"\n    ## @param metrics.kafka.tlsCaCert The secret key from the certificatesSecret or tlsCaSecret if 'ca-cert' key different from the default (ca-file)\n    ##\n    tlsCaCert: ca-file\n    ## @param metrics.kafka.extraFlags Extra flags to be passed to Kafka exporter\n    ## e.g:\n    ## extraFlags:\n    ##   tls.insecure-skip-tls-verify: \"\"\n    ##   web.telemetry-path: \"/metrics\"\n    ##\n    extraFlags: {}\n    ## @param metrics.kafka.command Override Kafka exporter container command\n    ##\n    command: []\n    ## @param metrics.kafka.args Override Kafka exporter container arguments\n    ##\n    args: []\n    ## @param metrics.kafka.containerPorts.metrics Kafka exporter metrics container port\n    ##\n    containerPorts:\n      metrics: 9308\n    ## Kafka exporter resource requests and limits\n    ## ref: https://kubernetes.io/docs/user-guide/compute-resources/\n    ## @param metrics.kafka.resources.limits The resources limits for the container\n    ## @param metrics.kafka.resources.requests The requested resources for the container\n    ##\n    resources:\n      limits: {}\n      requests: {}\n    ## Kafka exporter pods' Security Context\n    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-pod\n    ## @param metrics.kafka.podSecurityContext.enabled Enable security context for the pods\n    ## @param metrics.kafka.podSecurityContext.fsGroup Set Kafka exporter pod's Security Context fsGroup\n    ##\n    podSecurityContext:\n      enabled: true\n      fsGroup: 1001\n    ## Kafka exporter containers' Security Context\n    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-container\n    ## @param metrics.kafka.containerSecurityContext.enabled Enable Kafka exporter containers' Security Context\n    ## @param metrics.kafka.containerSecurityContext.runAsUser Set Kafka exporter containers' Security Context runAsUser\n    ## @param metrics.kafka.containerSecurityContext.runAsNonRoot Set Kafka exporter containers' Security Context runAsNonRoot\n    ## e.g:\n    ##   containerSecurityContext:\n    ##     enabled: true\n    ##     capabilities:\n    ##       drop: [\"NET_RAW\"]\n    ##     readOnlyRootFilesystem: true\n    ##\n    containerSecurityContext:\n      enabled: true\n      runAsUser: 1001\n      runAsNonRoot: true\n    ## @param metrics.kafka.hostAliases Kafka exporter pods host aliases\n    ## https://kubernetes.io/docs/concepts/services-networking/add-entries-to-pod-etc-hosts-with-host-aliases/\n    ##\n    hostAliases: []\n    ## @param metrics.kafka.podLabels Extra labels for Kafka exporter pods\n    ## Ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/\n    ##\n    podLabels: {}\n    ## @param metrics.kafka.podAnnotations Extra annotations for Kafka exporter pods\n    ## ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/annotations/\n    ##\n    podAnnotations: {}\n    ## @param metrics.kafka.podAffinityPreset Pod affinity preset. Ignored if `metrics.kafka.affinity` is set. Allowed values: `soft` or `hard`\n    ## ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity\n    ##\n    podAffinityPreset: \"\"\n    ## @param metrics.kafka.podAntiAffinityPreset Pod anti-affinity preset. Ignored if `metrics.kafka.affinity` is set. Allowed values: `soft` or `hard`\n    ## Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#inter-pod-affinity-and-anti-affinity\n    ##\n    podAntiAffinityPreset: soft\n    ## Node metrics.kafka.affinity preset\n    ## Ref: https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/#node-affinity\n    ##\n    nodeAffinityPreset:\n      ## @param metrics.kafka.nodeAffinityPreset.type Node affinity preset type. Ignored if `metrics.kafka.affinity` is set. Allowed values: `soft` or `hard`\n      ##\n      type: \"\"\n      ## @param metrics.kafka.nodeAffinityPreset.key Node label key to match Ignored if `metrics.kafka.affinity` is set.\n      ## E.g.\n      ## key: \"kubernetes.io/e2e-az-name\"\n      ##\n      key: \"\"\n      ## @param metrics.kafka.nodeAffinityPreset.values Node label values to match. Ignored if `metrics.kafka.affinity` is set.\n      ## E.g.\n      ## values:\n      ##   - e2e-az1\n      ##   - e2e-az2\n      ##\n      values: []\n    ## @param metrics.kafka.affinity Affinity for pod assignment\n    ## Ref: https://kubernetes.io/docs/concepts/configuration/assign-pod-node/#affinity-and-anti-affinity\n    ## Note: metrics.kafka.podAffinityPreset, metrics.kafka.podAntiAffinityPreset, and metrics.kafka.nodeAffinityPreset will be ignored when it's set\n    ##\n    affinity: {}\n    ## @param metrics.kafka.nodeSelector Node labels for pod assignment\n    ## Ref: https://kubernetes.io/docs/user-guide/node-selection/\n    ##\n    nodeSelector: {}\n    ## @param metrics.kafka.tolerations Tolerations for pod assignment\n    ## Ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/\n    ##\n    tolerations: []\n    ## @param metrics.kafka.schedulerName Name of the k8s scheduler (other than default) for Kafka exporter\n    ## ref: https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/\n    ##\n    schedulerName: \"\"\n    ## @param metrics.kafka.priorityClassName Kafka exporter pods' priorityClassName\n    ##\n    priorityClassName: \"\"\n    ## @param metrics.kafka.topologySpreadConstraints Topology Spread Constraints for pod assignment\n    ## https://kubernetes.io/docs/concepts/workloads/pods/pod-topology-spread-constraints/\n    ## The value is evaluated as a template\n    ##\n    topologySpreadConstraints: []\n    ## @param metrics.kafka.extraVolumes Optionally specify extra list of additional volumes for the Kafka exporter pod(s)\n    ## e.g:\n    ## extraVolumes:\n    ##   - name: kafka-jaas\n    ##     secret:\n    ##       secretName: kafka-jaas\n    ##\n    extraVolumes: []\n    ## @param metrics.kafka.extraVolumeMounts Optionally specify extra list of additional volumeMounts for the Kafka exporter container(s)\n    ## extraVolumeMounts:\n    ##   - name: kafka-jaas\n    ##     mountPath: /bitnami/kafka/config/kafka_jaas.conf\n    ##     subPath: kafka_jaas.conf\n    ##\n    extraVolumeMounts: []\n    ## @param metrics.kafka.sidecars Add additional sidecar containers to the Kafka exporter pod(s)\n    ## e.g:\n    ## sidecars:\n    ##   - name: your-image-name\n    ##     image: your-image\n    ##     imagePullPolicy: Always\n    ##     ports:\n    ##       - name: portname\n    ##         containerPort: 1234\n    ##\n    sidecars: []\n    ## @param metrics.kafka.initContainers Add init containers to the Kafka exporter pods\n    ## e.g:\n    ## initContainers:\n    ##   - name: your-image-name\n    ##     image: your-image\n    ##     imagePullPolicy: Always\n    ##     ports:\n    ##       - name: portname\n    ##         containerPort: 1234\n    ##\n    initContainers: []\n    ## Kafka exporter service configuration\n    ##\n    service:\n      ## @param metrics.kafka.service.ports.metrics Kafka exporter metrics service port\n      ##\n      ports:\n        metrics: 9308\n      ## @param metrics.kafka.service.clusterIP Static clusterIP or None for headless services\n      ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#choosing-your-own-ip-address\n      ##\n      clusterIP: \"\"\n      ## @param metrics.kafka.service.sessionAffinity Control where client requests go, to the same pod or round-robin\n      ## Values: ClientIP or None\n      ## ref: https://kubernetes.io/docs/user-guide/services/\n      ##\n      sessionAffinity: None\n      ## @param metrics.kafka.service.annotations [object] Annotations for the Kafka exporter service\n      ##\n      annotations:\n        prometheus.io/scrape: \"true\"\n        prometheus.io/port: \"{{ .Values.metrics.kafka.service.ports.metrics }}\"\n        prometheus.io/path: \"/metrics\"\n    ## Kafka exporter pods ServiceAccount\n    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/\n    ##\n    serviceAccount:\n      ## @param metrics.kafka.serviceAccount.create Enable creation of ServiceAccount for Kafka exporter pods\n      ##\n      create: true\n      ## @param metrics.kafka.serviceAccount.name The name of the service account to use. If not set and `create` is `true`, a name is generated\n      ## If not set and create is true, a name is generated using the kafka.metrics.kafka.serviceAccountName template\n      ##\n      name: \"\"\n      ## @param metrics.kafka.serviceAccount.automountServiceAccountToken Allows auto mount of ServiceAccountToken on the serviceAccount created\n      ## Can be set to false if pods using this serviceAccount do not need to use K8s API\n      ##\n      automountServiceAccountToken: true\n  ## Prometheus JMX exporter: exposes the majority of Kafkas metrics\n  ##\n  jmx:\n    ## @param metrics.jmx.enabled Whether or not to expose JMX metrics to Prometheus\n    ##\n    enabled: false\n    ## Bitnami JMX exporter image\n    ## ref: https://hub.docker.com/r/bitnami/jmx-exporter/tags/\n    ## @param metrics.jmx.image.registry JMX exporter image registry\n    ## @param metrics.jmx.image.repository JMX exporter image repository\n    ## @param metrics.jmx.image.tag JMX exporter image tag (immutable tags are recommended)\n    ## @param metrics.jmx.image.digest JMX exporter image digest in the way sha256:aa.... Please note this parameter, if set, will override the tag\n    ## @param metrics.jmx.image.pullPolicy JMX exporter image pull policy\n    ## @param metrics.jmx.image.pullSecrets Specify docker-registry secret names as an array\n    ##\n    image:\n      registry: docker.io\n      repository: bitnami/jmx-exporter\n      tag: 0.17.2-debian-11-r29\n      digest: \"\"\n      ## Specify a imagePullPolicy\n      ## Defaults to 'Always' if image tag is 'latest', else set to 'IfNotPresent'\n      ## ref: https://kubernetes.io/docs/user-guide/images/#pre-pulling-images\n      ##\n      pullPolicy: IfNotPresent\n      ## Optionally specify an array of imagePullSecrets (secrets must be manually created in the namespace)\n      ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/pull-image-private-registry/\n      ## e.g:\n      ## pullSecrets:\n      ##   - myRegistryKeySecretName\n      ##\n      pullSecrets: []\n    ## Prometheus JMX exporter containers' Security Context\n    ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-container\n    ## @param metrics.jmx.containerSecurityContext.enabled Enable Prometheus JMX exporter containers' Security Context\n    ## @param metrics.jmx.containerSecurityContext.runAsUser Set Prometheus JMX exporter containers' Security Context runAsUser\n    ## @param metrics.jmx.containerSecurityContext.runAsNonRoot Set Prometheus JMX exporter containers' Security Context runAsNonRoot\n    ## e.g:\n    ##   containerSecurityContext:\n    ##     enabled: true\n    ##     capabilities:\n    ##       drop: [\"NET_RAW\"]\n    ##     readOnlyRootFilesystem: true\n    ##\n    containerSecurityContext:\n      enabled: true\n      runAsUser: 1001\n      runAsNonRoot: true\n    ## @param metrics.jmx.containerPorts.metrics Prometheus JMX exporter metrics container port\n    ##\n    containerPorts:\n      metrics: 5556\n    ## Prometheus JMX exporter resource requests and limits\n    ## ref: https://kubernetes.io/docs/user-guide/compute-resources/\n    ## @param metrics.jmx.resources.limits The resources limits for the JMX exporter container\n    ## @param metrics.jmx.resources.requests The requested resources for the JMX exporter container\n    ##\n    resources:\n      limits: {}\n      requests: {}\n    ## Prometheus JMX exporter service configuration\n    ##\n    service:\n      ## @param metrics.jmx.service.ports.metrics Prometheus JMX exporter metrics service port\n      ##\n      ports:\n        metrics: 5556\n      ## @param metrics.jmx.service.clusterIP Static clusterIP or None for headless services\n      ## ref: https://kubernetes.io/docs/concepts/services-networking/service/#choosing-your-own-ip-address\n      ##\n      clusterIP: \"\"\n      ## @param metrics.jmx.service.sessionAffinity Control where client requests go, to the same pod or round-robin\n      ## Values: ClientIP or None\n      ## ref: https://kubernetes.io/docs/user-guide/services/\n      ##\n      sessionAffinity: None\n      ## @param metrics.jmx.service.annotations [object] Annotations for the Prometheus JMX exporter service\n      ##\n      annotations:\n        prometheus.io/scrape: \"true\"\n        prometheus.io/port: \"{{ .Values.metrics.jmx.service.ports.metrics }}\"\n        prometheus.io/path: \"/\"\n    ## @param metrics.jmx.whitelistObjectNames Allows setting which JMX objects you want to expose to via JMX stats to JMX exporter\n    ## Only whitelisted values will be exposed via JMX exporter. They must also be exposed via Rules. To expose all metrics\n    ## (warning its crazy excessive and they aren't formatted in a prometheus style) (1) `whitelistObjectNames: []`\n    ## (2) commented out above `overrideConfig`.\n    ##\n    whitelistObjectNames:\n      - kafka.controller:*\n      - kafka.server:*\n      - java.lang:*\n      - kafka.network:*\n      - kafka.log:*\n    ## @param metrics.jmx.config [string] Configuration file for JMX exporter\n    ## Specify content for jmx-kafka-prometheus.yml. Evaluated as a template\n    ##\n    ## Credits to the incubator/kafka chart for the JMX configuration.\n    ## https://github.com/helm/charts/tree/master/incubator/kafka\n    ##\n    config: |-\n      jmxUrl: service:jmx:rmi:///jndi/rmi://127.0.0.1:5555/jmxrmi\n      lowercaseOutputName: true\n      lowercaseOutputLabelNames: true\n      ssl: false\n      {{- if .Values.metrics.jmx.whitelistObjectNames }}\n      whitelistObjectNames: [\"{{ join \"\\\",\\\"\" .Values.metrics.jmx.whitelistObjectNames }}\"]\n      {{- end }}\n    ## @param metrics.jmx.existingConfigmap Name of existing ConfigMap with JMX exporter configuration\n    ## NOTE: This will override metrics.jmx.config\n    ##\n    existingConfigmap: \"\"\n    ## @param metrics.jmx.extraRules  Add extra rules to JMX exporter configuration\n    ## e.g:\n    ## extraRules: |-\n    ##  - pattern: kafka.server\u003ctype=socket-server-metrics, listener=(.+), networkProcessor=(.+)\u003e\u003c\u003e(connection-count)\n    ##    name: kafka_server_socket_server_metrics_$3\n    ##    labels:\n    ##      listener: $1\n    extraRules: \"\"\n  ## Prometheus Operator ServiceMonitor configuration\n  ##\n  serviceMonitor:\n    ## @param metrics.serviceMonitor.enabled if `true`, creates a Prometheus Operator ServiceMonitor (requires `metrics.kafka.enabled` or `metrics.jmx.enabled` to be `true`)\n    ##\n    enabled: false\n    ## @param metrics.serviceMonitor.namespace Namespace in which Prometheus is running\n    ##\n    namespace: \"\"\n    ## @param metrics.serviceMonitor.interval Interval at which metrics should be scraped\n    ## ref: https://github.com/coreos/prometheus-operator/blob/master/Documentation/api.md#endpoint\n    ##\n    interval: \"\"\n    ## @param metrics.serviceMonitor.scrapeTimeout Timeout after which the scrape is ended\n    ## ref: https://github.com/coreos/prometheus-operator/blob/master/Documentation/api.md#endpoint\n    ##\n    scrapeTimeout: \"\"\n    ## @param metrics.serviceMonitor.labels Additional labels that can be used so ServiceMonitor will be discovered by Prometheus\n    ##\n    labels: {}\n    ## @param metrics.serviceMonitor.selector Prometheus instance selector labels\n    ## ref: https://github.com/bitnami/charts/tree/main/bitnami/prometheus-operator#prometheus-configuration\n    ##\n    selector: {}\n    ## @param metrics.serviceMonitor.relabelings RelabelConfigs to apply to samples before scraping\n    ##\n    relabelings: []\n    ## @param metrics.serviceMonitor.metricRelabelings MetricRelabelConfigs to apply to samples before ingestion\n    ##\n    metricRelabelings: []\n    ## @param metrics.serviceMonitor.honorLabels Specify honorLabels parameter to add the scrape endpoint\n    ##\n    honorLabels: false\n    ## @param metrics.serviceMonitor.jobLabel The name of the label on the target service to use as the job name in prometheus.\n    ##\n    jobLabel: \"\"\n\n  prometheusRule:\n    ## @param metrics.prometheusRule.enabled if `true`, creates a Prometheus Operator PrometheusRule (requires `metrics.kafka.enabled` or `metrics.jmx.enabled` to be `true`)\n    ##\n    enabled: false\n    ## @param metrics.prometheusRule.namespace Namespace in which Prometheus is running\n    ##\n    namespace: \"\"\n    ## @param metrics.prometheusRule.labels Additional labels that can be used so PrometheusRule will be discovered by Prometheus\n    ##\n    labels: {}\n    ## @param metrics.prometheusRule.groups Prometheus Rule Groups for Kafka\n    ##\n    groups: []\n\n## @section Kafka provisioning parameters\n\n## Kafka provisioning\n##\nprovisioning:\n  ## @param provisioning.enabled Enable kafka provisioning Job\n  ##\n  enabled: true\n  ## @param provisioning.numPartitions Default number of partitions for topics when unspecified\n  ##\n  numPartitions: 1\n  ## @param provisioning.replicationFactor Default replication factor for topics when unspecified\n  ##\n  replicationFactor: 1\n  ## @param provisioning.topics Kafka topics to provision\n\n  topics: \n  - name: \"dev.telemetry.denorm\"\n    partitions: 1\n    replicationFactor: 1\n    # https://kafka.apache.org/documentation/#topicconfigs\n    config:\n      max.message.bytes: 64000\n      flush.messages: 1\n  - name: \"dev.druid.events.telemetry\"\n    partitions: 1\n    replicationFactor: 1\n    # https://kafka.apache.org/documentation/#topicconfigs\n    config:\n      max.message.bytes: 64000\n      flush.messages: 1\n  - name: \"dev.druid.events.summary\"\n    partitions: 1\n    replicationFactor: 1\n    # https://kafka.apache.org/documentation/#topicconfigs\n    config:\n      max.message.bytes: 64000\n      flush.messages: 1\n  - name: \"dev.telemetry.failed\"\n    partitions: 1\n    replicationFactor: 1\n    # https://kafka.apache.org/documentation/#topicconfigs\n    config:\n      max.message.bytes: 64000\n      flush.messages: 1\n  - name: \"dev.telemetry.duplicate\"\n    partitions: 1\n    replicationFactor: 1\n    # https://kafka.apache.org/documentation/#topicconfigs\n    config:\n      max.message.bytes: 64000\n      flush.messages: 1\n  \n  ## @param provisioning.nodeSelector Node labels for pod assignment\n  ## Ref: https://kubernetes.io/docs/user-guide/node-selection/\n  ##\n  nodeSelector: {}\n  ## @param provisioning.tolerations Tolerations for pod assignment\n  ## Ref: https://kubernetes.io/docs/concepts/configuration/taint-and-toleration/\n  ##\n  tolerations: []\n  ## @param provisioning.extraProvisioningCommands Extra commands to run to provision cluster resources\n  ## - echo \"Allow user to consume from any topic\"\n  ## - \u003e-\n  ##   /opt/bitnami/kafka/bin/kafka-acls.sh\n  ##   --bootstrap-server $KAFKA_SERVICE\n  ##   --command-config $CLIENT_CONF\n  ##   --add\n  ##   --allow-principal User:user\n  ##   --consumer --topic '*'\n  ## - \"/opt/bitnami/kafka/bin/kafka-acls.sh\n  ##      --bootstrap-server $KAFKA_SERVICE\n  ##      --command-config $CLIENT_CONF\n  ##      --list\"\n  ##\n  extraProvisioningCommands: []\n  ## @param provisioning.parallel Number of provisioning commands to run at the same time\n  ##\n  parallel: 1\n  ## @param provisioning.preScript Extra bash script to run before topic provisioning. $CLIENT_CONF is path to properties file with most needed configurations\n  ##\n  preScript: \"\"\n  ## @param provisioning.postScript Extra bash script to run after topic provisioning. $CLIENT_CONF is path to properties file with most needed configurations\n  ##\n  postScript: \"\"\n  ## Auth Configuration for kafka provisioning Job\n  ##\n  auth:\n    ## TLS configuration for kafka provisioning Job\n    ##\n    tls:\n      ## @param provisioning.auth.tls.type Format to use for TLS certificates. Allowed types: `jks` and `pem`.\n      ## Note: ignored if auth.tls.clientProtocol different from one of these values: \"tls\" \"mtls\" \"sasl_tls\".\n      ##\n      type: jks\n      ## @param provisioning.auth.tls.certificatesSecret Existing secret containing the TLS certificates for the Kafka provisioning Job.\n      ## When using 'jks' format for certificates, the secret should contain a truststore and a keystore.\n      ## When using 'pem' format for certificates, the secret should contain a public CA certificate, a public certificate and one private key.\n      ##\n      certificatesSecret: \"\"\n      ## @param provisioning.auth.tls.cert The secret key from the certificatesSecret if 'cert' key different from the default (tls.crt)\n      ##\n      cert: tls.crt\n      ## @param provisioning.auth.tls.key The secret key from the certificatesSecret if 'key' key different from the default (tls.key)\n      ##\n      key: tls.key\n      ## @param provisioning.auth.tls.caCert The secret key from the certificatesSecret if 'caCert' key different from the default (ca.crt)\n      ##\n      caCert: ca.crt\n      ## @param provisioning.auth.tls.keystore The secret key from the certificatesSecret if 'keystore' key different from the default (keystore.jks)\n      ##\n      keystore: keystore.jks\n      ## @param provisioning.auth.tls.truststore The secret key from the certificatesSecret if 'truststore' key different from the default (truststore.jks)\n      ##\n      truststore: truststore.jks\n      ## @param provisioning.auth.tls.passwordsSecret Name of the secret containing passwords to access the JKS files or PEM key when they are password-protected.\n      ## It should contain two keys called \"keystore-password\" and \"truststore-password\", or \"key-password\" if using a password-protected PEM key.\n      ##\n      passwordsSecret: \"\"\n      ## @param provisioning.auth.tls.keyPasswordSecretKey The secret key from the passwordsSecret if 'keyPasswordSecretKey' key different from the default (key-password)\n      ## Note: must not be used if `passwordsSecret` is not defined.\n      ##\n      keyPasswordSecretKey: key-password\n      ## @param provisioning.auth.tls.keystorePasswordSecretKey The secret key from the passwordsSecret if 'keystorePasswordSecretKey' key different from the default (keystore-password)\n      ## Note: must not be used if `passwordsSecret` is not defined.\n      ##\n      keystorePasswordSecretKey: keystore-password\n      ## @param provisioning.auth.tls.truststorePasswordSecretKey The secret key from the passwordsSecret if 'truststorePasswordSecretKey' key different from the default (truststore-password)\n      ## Note: must not be used if `passwordsSecret` is not defined.\n      ##\n      truststorePasswordSecretKey: truststore-password\n      ## @param provisioning.auth.tls.keyPassword Password to access the password-protected PEM key if necessary. Ignored if 'passwordsSecret' is provided.\n      ##\n      keyPassword: \"\"\n      ## @param provisioning.auth.tls.keystorePassword Password to access the JKS keystore. Ignored if 'passwordsSecret' is provided.\n      ##\n      keystorePassword: \"\"\n      ## @param provisioning.auth.tls.truststorePassword Password to access the JKS truststore. Ignored if 'passwordsSecret' is provided.\n      ##\n      truststorePassword: \"\"\n  ## @param provisioning.command Override provisioning container command\n  ##\n  command: []\n  ## @param provisioning.args Override provisioning container arguments\n  ##\n  args: []\n  ## @param provisioning.extraEnvVars Extra environment variables to add to the provisioning pod\n  ## e.g:\n  ## extraEnvVars:\n  ##   - name: KAFKA_CFG_BACKGROUND_THREADS\n  ##     value: \"10\"\n  ##\n  extraEnvVars: []\n  ## @param provisioning.extraEnvVarsCM ConfigMap with extra environment variables\n  ##\n  extraEnvVarsCM: \"\"\n  ## @param provisioning.extraEnvVarsSecret Secret with extra environment variables\n  ##\n  extraEnvVarsSecret: \"\"\n  ## @param provisioning.podAnnotations Extra annotations for Kafka provisioning pods\n  ##\n  podAnnotations: {}\n  ## @param provisioning.podLabels Extra labels for Kafka provisioning pods\n  ## Ref: https://kubernetes.io/docs/concepts/overview/working-with-objects/labels/\n  ##\n  podLabels: {}\n  ## Kafka provisioning pods ServiceAccount\n  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/configure-service-account/\n  ##\n  serviceAccount:\n    ## @param provisioning.serviceAccount.create Enable creation of ServiceAccount for Kafka provisioning pods\n    ##\n    create: false\n    ## @param provisioning.serviceAccount.name The name of the service account to use. If not set and `create` is `true`, a name is generated\n    ## If not set and create is true, a name is generated using the provisioning.serviceAccount.name template\n    ##\n    name: \"\"\n    ## @param provisioning.serviceAccount.automountServiceAccountToken Allows auto mount of ServiceAccountToken on the serviceAccount created\n    ## Can be set to false if pods using this serviceAccount do not need to use K8s API\n    ##\n    automountServiceAccountToken: true\n  ## Kafka provisioning resource requests and limits\n  ## ref: https://kubernetes.io/docs/user-guide/compute-resources/\n  ## @param provisioning.resources.limits The resources limits for the Kafka provisioning container\n  ## @param provisioning.resources.requests The requested resources for the Kafka provisioning container\n  ##\n  resources:\n    limits: {}\n    requests: {}\n  ## Kafka provisioning pods' Security Context\n  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-pod\n  ## @param provisioning.podSecurityContext.enabled Enable security context for the pods\n  ## @param provisioning.podSecurityContext.fsGroup Set Kafka provisioning pod's Security Context fsGroup\n  ##\n  podSecurityContext:\n    enabled: true\n    fsGroup: 1001\n  ## Kafka provisioning containers' Security Context\n  ## ref: https://kubernetes.io/docs/tasks/configure-pod-container/security-context/#set-the-security-context-for-a-container\n  ## @param provisioning.containerSecurityContext.enabled Enable Kafka provisioning containers' Security Context\n  ## @param provisioning.containerSecurityContext.runAsUser Set Kafka provisioning containers' Security Context runAsUser\n  ## @param provisioning.containerSecurityContext.runAsNonRoot Set Kafka provisioning containers' Security Context runAsNonRoot\n  ## e.g:\n  ##   containerSecurityContext:\n  ##     enabled: true\n  ##     capabilities:\n  ##       drop: [\"NET_RAW\"]\n  ##     readOnlyRootFilesystem: true\n  ##\n  containerSecurityContext:\n    enabled: true\n    runAsUser: 1001\n    runAsNonRoot: true\n  ## @param provisioning.schedulerName Name of the k8s scheduler (other than default) for kafka provisioning\n  ## ref: https://kubernetes.io/docs/tasks/administer-cluster/configure-multiple-schedulers/\n  ##\n  schedulerName: \"\"\n  ## @param provisioning.extraVolumes Optionally specify extra list of additional volumes for the Kafka provisioning pod(s)\n  ## e.g:\n  ## extraVolumes:\n  ##   - name: kafka-jaas\n  ##     secret:\n  ##       secretName: kafka-jaas\n  ##\n  extraVolumes: []\n  ## @param provisioning.extraVolumeMounts Optionally specify extra list of additional volumeMounts for the Kafka provisioning container(s)\n  ## extraVolumeMounts:\n  ##   - name: kafka-jaas\n  ##     mountPath: /bitnami/kafka/config/kafka_jaas.conf\n  ##     subPath: kafka_jaas.conf\n  ##\n  extraVolumeMounts: []\n  ## @param provisioning.sidecars Add additional sidecar containers to the Kafka provisioning pod(s)\n  ## e.g:\n  ## sidecars:\n  ##   - name: your-image-name\n  ##     image: your-image\n  ##     imagePullPolicy: Always\n  ##     ports:\n  ##       - name: portname\n  ##         containerPort: 1234\n  ##\n  sidecars: []\n  ## @param provisioning.initContainers Add additional Add init containers to the Kafka provisioning pod(s)\n  ## e.g:\n  ## initContainers:\n  ##   - name: your-image-name\n  ##     image: your-image\n  ##     imagePullPolicy: Always\n  ##     ports:\n  ##       - name: portname\n  ##         containerPort: 1234\n  ##\n  initContainers: []\n  ## @param provisioning.waitForKafka If true use an init container to wait until kafka is ready before starting provisioning\n  ##\n  waitForKafka: true\n\n## @section ZooKeeper chart parameters\n\n## ZooKeeper chart configuration\n## https://github.com/bitnami/charts/blob/main/bitnami/zookeeper/values.yaml\n##\nzookeeper:\n  ## @param zookeeper.enabled Switch to enable or disable the ZooKeeper helm chart\n  ##\n  enabled: true\n  ## @param zookeeper.replicaCount Number of ZooKeeper nodes\n  ##\n  replicaCount: 1\n  ## ZooKeeper authenticaiton\n  ##\n  auth:\n    client:\n      ## @param zookeeper.auth.client.enabled Enable ZooKeeper auth\n      ##\n      enabled: false\n      ## @param zookeeper.auth.client.clientUser User that will use ZooKeeper clients to auth\n      ##\n      clientUser: \"\"\n      ## @param zookeeper.auth.client.clientPassword Password that will use ZooKeeper clients to auth\n      ##\n      clientPassword: \"\"\n      ## @param zookeeper.auth.client.serverUsers Comma, semicolon or whitespace separated list of user to be created. Specify them as a string, for example: \"user1,user2,admin\"\n      ##\n      serverUsers: \"\"\n      ## @param zookeeper.auth.client.serverPasswords Comma, semicolon or whitespace separated list of passwords to assign to users when created. Specify them as a string, for example: \"pass4user1, pass4user2, pass4admin\"\n      ##\n      serverPasswords: \"\"\n  ## ZooKeeper Persistence parameters\n  ## ref: https://kubernetes.io/docs/user-guide/persistent-volumes/\n  ## @param zookeeper.persistence.enabled Enable persistence on ZooKeeper using PVC(s)\n  ## @param zookeeper.persistence.storageClass Persistent Volume storage class\n  ## @param zookeeper.persistence.accessModes Persistent Volume access modes\n  ## @param zookeeper.persistence.size Persistent Volume size\n  ##\n  persistence:\n    enabled: true\n    storageClass: \"\"\n    accessModes:\n      - ReadWriteOnce\n    size: 8Gi\n\n## External Zookeeper Configuration\n## All of these values are only used if `zookeeper.enabled=false`\n##\nexternalZookeeper:\n  ## @param externalZookeeper.servers List of external zookeeper servers to use. Typically used in combination with 'zookeeperChrootPath'.\n  ##\n  servers: []\n"
            ],
            "verify": false,
            "version": "20.0.2",
            "wait": true,
            "wait_for_jobs": true
          },
          "sensitive_attributes": [],
          "private": "bnVsbA==",
          "dependencies": [
            "kind_cluster.one-click"
          ]
        }
      ]
    },
    {
      "mode": "managed",
      "type": "helm_release",
      "name": "logstash",
      "provider": "provider[\"registry.terraform.io/hashicorp/helm\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "atomic": false,
            "chart": "../../helm_charts/logstash",
            "cleanup_on_fail": false,
            "create_namespace": true,
            "dependency_update": true,
            "description": null,
            "devel": null,
            "disable_crd_hooks": false,
            "disable_openapi_validation": false,
            "disable_webhooks": false,
            "force_update": false,
            "id": "logstash",
            "keyring": null,
            "lint": false,
            "manifest": null,
            "max_history": 0,
            "metadata": [
              {
                "app_version": "8.6.2",
                "chart": "logstash",
                "name": "logstash",
                "namespace": "knowlg-db",
                "revision": 1,
                "values": "null",
                "version": "5.1.15"
              }
            ],
            "name": "logstash",
            "namespace": "knowlg-db",
            "pass_credentials": false,
            "postrender": [],
            "recreate_pods": false,
            "render_subchart_notes": true,
            "replace": false,
            "repository": null,
            "repository_ca_file": null,
            "repository_cert_file": null,
            "repository_key_file": null,
            "repository_password": null,
            "repository_username": null,
            "reset_values": false,
            "reuse_values": false,
            "set": [],
            "set_sensitive": [],
            "skip_crds": false,
            "status": "deployed",
            "timeout": 300,
            "values": null,
            "verify": false,
            "version": "5.1.15",
            "wait": true,
            "wait_for_jobs": true
          },
          "sensitive_attributes": [],
          "private": "bnVsbA==",
          "dependencies": [
            "kind_cluster.one-click"
          ]
        }
      ]
    },
    {
      "mode": "managed",
      "type": "helm_release",
      "name": "neo4j",
      "provider": "provider[\"registry.terraform.io/hashicorp/helm\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "atomic": false,
            "chart": "../../helm_charts/neo4j",
            "cleanup_on_fail": false,
            "create_namespace": true,
            "dependency_update": true,
            "description": null,
            "devel": null,
            "disable_crd_hooks": false,
            "disable_openapi_validation": false,
            "disable_webhooks": false,
            "force_update": false,
            "id": "neo4j",
            "keyring": null,
            "lint": false,
            "manifest": null,
            "max_history": 0,
            "metadata": [
              {
                "app_version": "1.0",
                "chart": "neo4j",
                "name": "neo4j",
                "namespace": "knowlg-db",
                "revision": 1,
                "values": "null",
                "version": "0.1.0"
              }
            ],
            "name": "neo4j",
            "namespace": "knowlg-db",
            "pass_credentials": false,
            "postrender": [],
            "recreate_pods": false,
            "render_subchart_notes": true,
            "replace": false,
            "repository": null,
            "repository_ca_file": null,
            "repository_cert_file": null,
            "repository_key_file": null,
            "repository_password": null,
            "repository_username": null,
            "reset_values": false,
            "reuse_values": false,
            "set": [],
            "set_sensitive": [],
            "skip_crds": false,
            "status": "deployed",
            "timeout": 300,
            "values": null,
            "verify": false,
            "version": "0.1.0",
            "wait": true,
            "wait_for_jobs": true
          },
          "sensitive_attributes": [],
          "private": "bnVsbA==",
          "dependencies": [
            "kind_cluster.one-click"
          ]
        }
      ]
    },
    {
      "mode": "managed",
      "type": "helm_release",
      "name": "redis",
      "provider": "provider[\"registry.terraform.io/hashicorp/helm\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "atomic": false,
            "chart": "../../helm_charts/redis",
            "cleanup_on_fail": false,
            "create_namespace": true,
            "dependency_update": true,
            "description": null,
            "devel": null,
            "disable_crd_hooks": false,
            "disable_openapi_validation": false,
            "disable_webhooks": false,
            "force_update": false,
            "id": "redis",
            "keyring": null,
            "lint": false,
            "manifest": null,
            "max_history": 0,
            "metadata": [
              {
                "app_version": "1.0",
                "chart": "redis",
                "name": "redis",
                "namespace": "knowlg-db",
                "revision": 1,
                "values": "null",
                "version": "0.1.0"
              }
            ],
            "name": "redis",
            "namespace": "knowlg-db",
            "pass_credentials": false,
            "postrender": [],
            "recreate_pods": false,
            "render_subchart_notes": true,
            "replace": false,
            "repository": null,
            "repository_ca_file": null,
            "repository_cert_file": null,
            "repository_key_file": null,
            "repository_password": null,
            "repository_username": null,
            "reset_values": false,
            "reuse_values": false,
            "set": [],
            "set_sensitive": [],
            "skip_crds": false,
            "status": "deployed",
            "timeout": 300,
            "values": null,
            "verify": false,
            "version": "0.1.0",
            "wait": true,
            "wait_for_jobs": true
          },
          "sensitive_attributes": [],
          "private": "bnVsbA==",
          "dependencies": [
            "kind_cluster.one-click"
          ]
        }
      ]
    },
    {
      "mode": "managed",
      "type": "helm_release",
      "name": "taxonomy",
      "provider": "provider[\"registry.terraform.io/hashicorp/helm\"]",
      "instances": [
        {
          "status": "tainted",
          "schema_version": 0,
          "attributes": {
            "atomic": false,
            "chart": "../../helm_charts/taxonomy",
            "cleanup_on_fail": false,
            "create_namespace": true,
            "dependency_update": true,
            "description": null,
            "devel": null,
            "disable_crd_hooks": false,
            "disable_openapi_validation": false,
            "disable_webhooks": false,
            "force_update": false,
            "id": "taxonomy",
            "keyring": null,
            "lint": false,
            "manifest": null,
            "max_history": 0,
            "metadata": [
              {
                "app_version": "1.0",
                "chart": "taxonomy",
                "name": "taxonomy",
                "namespace": "knowlg-db",
                "revision": 1,
                "values": "{}",
                "version": "0.1.0"
              }
            ],
            "name": "taxonomy",
            "namespace": "knowlg-db",
            "pass_credentials": false,
            "postrender": [],
            "recreate_pods": false,
            "render_subchart_notes": true,
            "replace": false,
            "repository": null,
            "repository_ca_file": null,
            "repository_cert_file": null,
            "repository_key_file": null,
            "repository_password": null,
            "repository_username": null,
            "reset_values": false,
            "reuse_values": false,
            "set": [],
            "set_sensitive": [],
            "skip_crds": false,
            "status": "failed",
            "timeout": 300,
            "values": null,
            "verify": false,
            "version": "0.1.0",
            "wait": true,
            "wait_for_jobs": true
          },
          "sensitive_attributes": [],
          "private": "bnVsbA==",
          "dependencies": [
            "kind_cluster.one-click"
          ]
        }
      ]
    },
    {
      "mode": "managed",
      "type": "kind_cluster",
      "name": "one-click",
      "provider": "provider[\"registry.terraform.io/kyma-incubator/kind\"]",
      "instances": [
        {
          "schema_version": 0,
          "attributes": {
            "client_certificate": "-----BEGIN CERTIFICATE-----\nMIIDITCCAgmgAwIBAgIIU6PEtyrh6EQwDQYJKoZIhvcNAQELBQAwFTETMBEGA1UE\nAxMKa3ViZXJuZXRlczAeFw0yMzAzMjgwMzU1MjZaFw0yNDAzMjcwMzU1MjhaMDQx\nFzAVBgNVBAoTDnN5c3RlbTptYXN0ZXJzMRkwFwYDVQQDExBrdWJlcm5ldGVzLWFk\nbWluMIIBIjANBgkqhkiG9w0BAQEFAAOCAQ8AMIIBCgKCAQEAntJBGxbamEyt8v/e\nGtmeSN/Dg9K0DYpKdthXA223UcFSza4RjMCo/cuwgcUB7MnRIPhTnR8/L4j16Dh7\nGi2e2Y52eOcHFykT7OsfY9blgbDaiyFEvv8fcDoOkFb4Acd6fI/lnP0+0XaE7CHR\nNpVUodC3KsR7US+/49Yzod/xrBXoxENp8RWDv+C4AsNtsc/C2oYDoeysFMzQgy1k\nl5sjsKlQ3apKKyxOtpZ4N1j4LZUwmVpc9iBBfLhklLmiqwIaDYNDoTvID59+cTda\nthAO0pvCEBZR/aJNLiD0ApbeCa184mOyobZWa43Zyw1N4rUTlN9vGxAF1EJMqNvT\nZATS+QIDAQABo1YwVDAOBgNVHQ8BAf8EBAMCBaAwEwYDVR0lBAwwCgYIKwYBBQUH\nAwIwDAYDVR0TAQH/BAIwADAfBgNVHSMEGDAWgBR2VBGD3GjdF/AQHDjWmm/zCwX2\nZjANBgkqhkiG9w0BAQsFAAOCAQEAUSa48JJgExqFenBcmJYFWrvaUqtBO9jxXYbg\n0CSG2CY88BwYLwuv4UXiDgbQlLXwbdWGRFK9gzawHHcFBVjmVUrt9vFhSQ/k8RYX\n6AIUCGCoaq0TBOI+fcdsSE1TT6zLjrabsiUsx61+7iA2dRDlhsDfflEKAtyNPqZi\n8DKPRlIQrr2h705winQjrdTxyY/eLXlH5PHSlM/LErco/HvXdcFvRr+1G9WRpzgK\nUbs145U20WU+SucC+Jjs1XMUjJkKMsto0/Xsbi7MJlQUkJ2MwtGlkp6p2AU+fUZk\nRWJoGuCPhvAfl5K9m5VJwTK4vIlmUE6TxdprgGQNlNa73NAa4Q==\n-----END CERTIFICATE-----\n",
            "client_key": "-----BEGIN RSA PRIVATE KEY-----\nMIIEpAIBAAKCAQEAntJBGxbamEyt8v/eGtmeSN/Dg9K0DYpKdthXA223UcFSza4R\njMCo/cuwgcUB7MnRIPhTnR8/L4j16Dh7Gi2e2Y52eOcHFykT7OsfY9blgbDaiyFE\nvv8fcDoOkFb4Acd6fI/lnP0+0XaE7CHRNpVUodC3KsR7US+/49Yzod/xrBXoxENp\n8RWDv+C4AsNtsc/C2oYDoeysFMzQgy1kl5sjsKlQ3apKKyxOtpZ4N1j4LZUwmVpc\n9iBBfLhklLmiqwIaDYNDoTvID59+cTdathAO0pvCEBZR/aJNLiD0ApbeCa184mOy\nobZWa43Zyw1N4rUTlN9vGxAF1EJMqNvTZATS+QIDAQABAoIBAEyX7ZoY3XcRk9pb\nF0wvoyxV7b6HQRo+lUbXcq9OnFgrObnDtucAiv9K2mbbEeCWO+sAl6JwzVIpZR6H\nDqdDVRZqpCwOjtbWkqtxgQPvQWPYXK04cCUEeK7w8NEfgB+riiDEbOHXKBJwbA5N\nCM6gGd6n/436j9ZJhutkBCaPD8gDTmZ/FijYzl+6pL92fOFvweCYkQrCnwJxVoGI\njsU7a2vx4tNa4gK6DF/etXpd5XGwncKx3723cVOFKq8iV1SuiK6nwT8n9YPuvG3s\nxuop6J/KWQVQe3Xke9kNg+qnB/xrPEfMJMM5+3UO8P/RTSR3AaHsjNXbTPm8UXYb\nQUJf43kCgYEAxeYgU/JKdff6v6DRuVdVGACH/35CpUxMHXztq6P+C0gHlEjb5Vxm\nByrcLgc6xojnNzshHUGwq7k/2zqmRDVh+8V40UUOE5GIOQJV4NUcv4CI/OkErfl5\ngfOqz7jmOKE1F8AIkTO39btUp3d0cN4umBBuw9L+Iyu2mH/Xig/sbm8CgYEAzXMY\nX22OpwHV5YJl2hD+Rv7HEg9imt65vwFEXocoIUZkSS64OMwFKCbkvNbIc6Sps67/\nQFLfh/AIFAhwNEzaP0D9kaZpLxtrANba9QT0hLdoxDc9cA/CNG5vO6FBsN2VHGw0\ns3DB+wdChun5Z4I7XWUgBaOH6GrAIba1JBrrCRcCgYEAp2phGuM0HsxkMkzIXzUE\nZcO9SWT02IXNNn0DS1r2hXCwCMACVuxt285kagPvsxkKEW1SPD/gR8X1wW7CTZ2j\ngKyz4sW6fM93IFNbd1KSeWcxfFNchBkys78BV60iBfJKygbIuJ26GIYbvXiO5xTu\n8fGk4sDSAcrvM9+i5cdGyr0CgYEAgoEf9E5FlXSnCJkiVbkBrNteXOyE+FeOqfQG\nF/3G0gxC2/Hfd8SxaeX62rGct0jbu5Xn8lYyQ8mHeCI8FBzVbeS8re6FVjUWbXwN\nriKtqDhRRoLIdgyskl2sLraqYcz/UQSzHWD895aO/eBWWxfw2czI4IwWYt6cmU3U\nFtE6h5UCgYB9ZTAWEFGmKusS3NMT9do5tCVB6Rca2woivCugtX1Lej/OtapA/nwI\n5BBpM2MfHgsZZW+GWqujN2ZYIXfL/6PNiOXw06MuMWJTgRHL2j/kVeS0Wo2dqAbu\nCf/7UVArE/usBnP6Qdue7HDEyAWZaU09R4M8sEa71D2BVV0VP6WdiA==\n-----END RSA PRIVATE KEY-----\n",
            "cluster_ca_certificate": "-----BEGIN CERTIFICATE-----\nMIIC5zCCAc+gAwIBAgIBADANBgkqhkiG9w0BAQsFADAVMRMwEQYDVQQDEwprdWJl\ncm5ldGVzMB4XDTIzMDMyODAzNTUyNloXDTMzMDMyNTAzNTUyNlowFTETMBEGA1UE\nAxMKa3ViZXJuZXRlczCCASIwDQYJKoZIhvcNAQEBBQADggEPADCCAQoCggEBAL5U\nuTVslBXDnjUNb/D6z71o8E7WlAgyp+oq7gYJALyarC41egt1NZlJD8GHD6+PzHbx\n3kwIMdcrUmzd0QTHX8nc72K53/mXxSgkBM8oISYqm5aHh1hasV1elQP9/j36Vfmt\n5L/uiUCVwcb3Wfx6Sj4tfPj61czuUUq6D+oVP2yi/0gtKyZzSCvFovZFYR8mFu4q\nkJ9oL59i4KJ/txjRu4ImhLumfBnFdwiy/kJx24VnZDURVjQJE6MruFzM8virB11m\nIXhpv6Zr/wP1UqY8lvEiFX9MfwI3RtlmlSbW+3mAImIadDWnDWVB4fjjCPtIsJS1\ndvP55cHuRA3NJY5hqK0CAwEAAaNCMEAwDgYDVR0PAQH/BAQDAgKkMA8GA1UdEwEB\n/wQFMAMBAf8wHQYDVR0OBBYEFHZUEYPcaN0X8BAcONaab/MLBfZmMA0GCSqGSIb3\nDQEBCwUAA4IBAQAfXZZ+raUxvTBY/e6TDAqSCq5uz9gUlT+eyVYzzmWOOjF+rwRS\n+HNNamZygWxo9w7H+AMWhyPHAuE4Zx7nIlGz3cTgcsQONtBhC5u+jQGK5TY/m/Rv\njQ9ceP1jnmZHBQx8pvOUhSoO08MqG7J1bycV2gkLgN/iU2PZ2I7ADN03K98ev8Ey\nmIBpKoow2qFlsfAb2EZV9akI0uraJQfoMGLbF4Ve2Z57HKEKAJITNfFKCa8J7Hij\njsW4tnzBzfA6cUvtHqDOv3x10cVYn6b+yh28bo+nMFhn20xbZ4vwDBy27TtSwuVW\ntgtV0WA7cgcZtQtnFy3NXpQ8qOWZeBPuW9jm\n-----END CERTIFICATE-----\n",
            "endpoint": "https://127.0.0.1:37145",
            "id": "one-click-",
            "kind_config": [
              {
                "api_version": "kind.x-k8s.io/v1alpha4",
                "containerd_config_patches": [],
                "kind": "Cluster",
                "networking": [],
                "node": [
                  {
                    "extra_mounts": [],
                    "extra_port_mappings": [
                      {
                        "container_port": 80,
                        "host_port": 80,
                        "listen_address": "",
                        "protocol": ""
                      },
                      {
                        "container_port": 443,
                        "host_port": 443,
                        "listen_address": "",
                        "protocol": ""
                      }
                    ],
                    "image": "",
                    "kubeadm_config_patches": [
                      "kind: InitConfiguration\nnodeRegistration:\n  kubeletExtraArgs:\n    node-labels: \"ingress-ready=true\"\n"
                    ],
                    "role": "control-plane"
                  },
                  {
                    "extra_mounts": [],
                    "extra_port_mappings": [],
                    "image": "",
                    "kubeadm_config_patches": [
                      "kind: InitConfiguration\nnodeRegistration:\n  kubeletExtraArgs:\n    node-labels: \"worker-node=true\"\n"
                    ],
                    "role": "worker"
                  },
                  {
                    "extra_mounts": [],
                    "extra_port_mappings": [],
                    "image": "",
                    "kubeadm_config_patches": [
                      "kind: InitConfiguration\nnodeRegistration:\n  kubeletExtraArgs:\n    node-labels: \"worker-node=true\"\n"
                    ],
                    "role": "worker"
                  },
                  {
                    "extra_mounts": [],
                    "extra_port_mappings": [],
                    "image": "",
                    "kubeadm_config_patches": [
                      "kind: InitConfiguration\nnodeRegistration:\n  kubeletExtraArgs:\n    node-labels: \"worker-node=true\"\n"
                    ],
                    "role": "worker"
                  }
                ]
              }
            ],
            "kubeconfig": "apiVersion: v1\nclusters:\n- cluster:\n    certificate-authority-data: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSUM1ekNDQWMrZ0F3SUJBZ0lCQURBTkJna3Foa2lHOXcwQkFRc0ZBREFWTVJNd0VRWURWUVFERXdwcmRXSmwKY201bGRHVnpNQjRYRFRJek1ETXlPREF6TlRVeU5sb1hEVE16TURNeU5UQXpOVFV5Tmxvd0ZURVRNQkVHQTFVRQpBeE1LYTNWaVpYSnVaWFJsY3pDQ0FTSXdEUVlKS29aSWh2Y05BUUVCQlFBRGdnRVBBRENDQVFvQ2dnRUJBTDVVCnVUVnNsQlhEbmpVTmIvRDZ6NzFvOEU3V2xBZ3lwK29xN2dZSkFMeWFyQzQxZWd0MU5abEpEOEdIRDYrUHpIYngKM2t3SU1kY3JVbXpkMFFUSFg4bmM3Mks1My9tWHhTZ2tCTThvSVNZcW01YUhoMWhhc1YxZWxRUDkvajM2VmZtdAo1TC91aVVDVndjYjNXZng2U2o0dGZQajYxY3p1VVVxNkQrb1ZQMnlpLzBndEt5WnpTQ3ZGb3ZaRllSOG1GdTRxCmtKOW9MNTlpNEtKL3R4alJ1NEltaEx1bWZCbkZkd2l5L2tKeDI0Vm5aRFVSVmpRSkU2TXJ1RnpNOHZpckIxMW0KSVhocHY2WnIvd1AxVXFZOGx2RWlGWDlNZndJM1J0bG1sU2JXKzNtQUltSWFkRFduRFdWQjRmampDUHRJc0pTMQpkdlA1NWNIdVJBM05KWTVocUswQ0F3RUFBYU5DTUVBd0RnWURWUjBQQVFIL0JBUURBZ0trTUE4R0ExVWRFd0VCCi93UUZNQU1CQWY4d0hRWURWUjBPQkJZRUZIWlVFWVBjYU4wWDhCQWNPTmFhYi9NTEJmWm1NQTBHQ1NxR1NJYjMKRFFFQkN3VUFBNElCQVFBZlhaWityYVV4dlRCWS9lNlREQXFTQ3E1dXo5Z1VsVCtleVZZenptV09PakYrcndSUworSE5OYW1aeWdXeG85dzdIK0FNV2h5UEhBdUU0Wng3bklsR3ozY1RnY3NRT050QmhDNXUralFHSzVUWS9tL1J2CmpROWNlUDFqbm1aSEJReDhwdk9VaFNvTzA4TXFHN0oxYnljVjJna0xnTi9pVTJQWjJJN0FETjAzSzk4ZXY4RXkKbUlCcEtvb3cycUZsc2ZBYjJFWlY5YWtJMHVyYUpRZm9NR0xiRjRWZTJaNTdIS0VLQUpJVE5mRktDYThKN0hpagpqc1c0dG56QnpmQTZjVXZ0SHFET3YzeDEwY1ZZbjZiK3loMjhibytuTUZobjIweGJaNHZ3REJ5MjdUdFN3dVZXCnRndFYwV0E3Y2djWnRRdG5GeTNOWHBROHFPV1plQlB1VzlqbQotLS0tLUVORCBDRVJUSUZJQ0FURS0tLS0tCg==\n    server: https://127.0.0.1:37145\n  name: kind-one-click\ncontexts:\n- context:\n    cluster: kind-one-click\n    user: kind-one-click\n  name: kind-one-click\ncurrent-context: kind-one-click\nkind: Config\npreferences: {}\nusers:\n- name: kind-one-click\n  user:\n    client-certificate-data: LS0tLS1CRUdJTiBDRVJUSUZJQ0FURS0tLS0tCk1JSURJVENDQWdtZ0F3SUJBZ0lJVTZQRXR5cmg2RVF3RFFZSktvWklodmNOQVFFTEJRQXdGVEVUTUJFR0ExVUUKQXhNS2EzVmlaWEp1WlhSbGN6QWVGdzB5TXpBek1qZ3dNelUxTWpaYUZ3MHlOREF6TWpjd016VTFNamhhTURReApGekFWQmdOVkJBb1REbk41YzNSbGJUcHRZWE4wWlhKek1Sa3dGd1lEVlFRREV4QnJkV0psY201bGRHVnpMV0ZrCmJXbHVNSUlCSWpBTkJna3Foa2lHOXcwQkFRRUZBQU9DQVE4QU1JSUJDZ0tDQVFFQW50SkJHeGJhbUV5dDh2L2UKR3RtZVNOL0RnOUswRFlwS2R0aFhBMjIzVWNGU3phNFJqTUNvL2N1d2djVUI3TW5SSVBoVG5SOC9MNGoxNkRoNwpHaTJlMlk1MmVPY0hGeWtUN09zZlk5YmxnYkRhaXlGRXZ2OGZjRG9Pa0ZiNEFjZDZmSS9sblAwKzBYYUU3Q0hSCk5wVlVvZEMzS3NSN1VTKy80OVl6b2QveHJCWG94RU5wOFJXRHYrQzRBc050c2MvQzJvWURvZXlzRk16UWd5MWsKbDVzanNLbFEzYXBLS3l4T3RwWjROMWo0TFpVd21WcGM5aUJCZkxoa2xMbWlxd0lhRFlORG9UdklENTkrY1RkYQp0aEFPMHB2Q0VCWlIvYUpOTGlEMEFwYmVDYTE4NG1PeW9iWldhNDNaeXcxTjRyVVRsTjl2R3hBRjFFSk1xTnZUClpBVFMrUUlEQVFBQm8xWXdWREFPQmdOVkhROEJBZjhFQkFNQ0JhQXdFd1lEVlIwbEJBd3dDZ1lJS3dZQkJRVUgKQXdJd0RBWURWUjBUQVFIL0JBSXdBREFmQmdOVkhTTUVHREFXZ0JSMlZCR0QzR2pkRi9BUUhEaldtbS96Q3dYMgpaakFOQmdrcWhraUc5dzBCQVFzRkFBT0NBUUVBVVNhNDhKSmdFeHFGZW5CY21KWUZXcnZhVXF0Qk85anhYWWJnCjBDU0cyQ1k4OEJ3WUx3dXY0VVhpRGdiUWxMWHdiZFdHUkZLOWd6YXdISGNGQlZqbVZVcnQ5dkZoU1EvazhSWVgKNkFJVUNHQ29hcTBUQk9JK2ZjZHNTRTFUVDZ6TGpyYWJzaVVzeDYxKzdpQTJkUkRsaHNEZmZsRUtBdHlOUHFaaQo4REtQUmxJUXJyMmg3MDV3aW5RanJkVHh5WS9lTFhsSDVQSFNsTS9MRXJjby9IdlhkY0Z2UnIrMUc5V1JwemdLClViczE0NVUyMFdVK1N1Y0MrSmpzMVhNVWpKa0tNc3RvMC9Yc2JpN01KbFFVa0oyTXd0R2xrcDZwMkFVK2ZVWmsKUldKb0d1Q1BodkFmbDVLOW01Vkp3VEs0dklsbVVFNlR4ZHByZ0dRTmxOYTczTkFhNFE9PQotLS0tLUVORCBDRVJUSUZJQ0FURS0tLS0tCg==\n    client-key-data: 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\n",
            "kubeconfig_path": "/home/stpl/.kube/config",
            "name": "one-click",
            "node_image": null,
            "timeouts": null,
            "wait_for_ready": true
          },
          "sensitive_attributes": [],
          "private": "eyJlMmJmYjczMC1lY2FhLTExZTYtOGY4OC0zNDM2M2JjN2M0YzAiOnsiY3JlYXRlIjozMDAwMDAwMDAwMDAsImRlbGV0ZSI6MzAwMDAwMDAwMDAwLCJ1cGRhdGUiOjMwMDAwMDAwMDAwMH19"
        }
      ]
    }
  ],
  "check_results": null
}
